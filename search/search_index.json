{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Scaling Gene Regulatory Networks Simulations \u00b6 Prerequisites \u00b6 Familiarity with bash and R Basic molecular biology knowledge preferred (gene expression and regulation) HPC knowledge preferred Learning objectives \u00b6 By the end of this workshop, participants should be able to: explain the concept of modelling and simulations, and how simulations can help answer research questions; briefly describe the main steps of gene expression, and explain what is a Gene Regulatory Network; list several classes of GRN models; generate a small random GRN with the sismonr package and simulate the expression of its gene; submit and manage jobs on a cluster using a scheduler and use software through environment modules; automate a large number of tasks on a HPC using array jobs. Some of the things we won't cover in this workshop \ud83d\ude45 \u00b6 How to : construct a mathematical or statistical model for a specific biological system of interest; estimate model parameters based on experimental data; reconstruct a GRN from experimental data; Any questions we don't have an answer for \ud83e\udd26 Content \u00b6 Before getting started, have a look at the Supplementary data for instructions on how to connect to NeSI Mahuika Jupyter. Lesson Overview 1. Introduction General overview of Simulations , Gene Regulatory Networks and Simulating Gene Regulatory networks 2. Getting started with sismonr Describe how sismonr package works and running the first simulation 3. Scaling up your work Introduction to High Performance Computing 4. Working with job scheduler Introduction to HPC Job Schedulers, Slurm Scheduler & life cycle of a Slurm job, Assessing resource utilisation and profiling 5. Parallel job arrays Introduction to specifications in Parallel Computing, Slurm Job arrays and Exercises on Scaling networks 6. Post-processing Interpreting sismonr output and Visualising the simlulations Supplementary-material.1 Supplementary-material.2 Schedule \u00b6 Day Time Topic 1 st day: 10am-12:30pm 1. Introduction 12:30pm-1:30pm Lunch break 1:30pm-2:30pm 2. Getting started with sismonr 2:30pm-3.30pm 3. Scaling up your work 4. Working with job scheduler 2 nd day: 10am-12pm 5. Automating large number of tasks 12pm-1pm Lunch break 1pm-2.30pm 5. Post-processing 2.30pm - Question time","title":"Home"},{"location":"#scaling-gene-regulatory-networks-simulations","text":"","title":"Scaling Gene Regulatory Networks Simulations"},{"location":"#prerequisites","text":"Familiarity with bash and R Basic molecular biology knowledge preferred (gene expression and regulation) HPC knowledge preferred","title":"Prerequisites"},{"location":"#learning-objectives","text":"By the end of this workshop, participants should be able to: explain the concept of modelling and simulations, and how simulations can help answer research questions; briefly describe the main steps of gene expression, and explain what is a Gene Regulatory Network; list several classes of GRN models; generate a small random GRN with the sismonr package and simulate the expression of its gene; submit and manage jobs on a cluster using a scheduler and use software through environment modules; automate a large number of tasks on a HPC using array jobs.","title":"Learning objectives"},{"location":"#some-of-the-things-we-wont-cover-in-this-workshop","text":"How to : construct a mathematical or statistical model for a specific biological system of interest; estimate model parameters based on experimental data; reconstruct a GRN from experimental data; Any questions we don't have an answer for \ud83e\udd26","title":"Some of the things we won't cover in this workshop \ud83d\ude45"},{"location":"#content","text":"Before getting started, have a look at the Supplementary data for instructions on how to connect to NeSI Mahuika Jupyter. Lesson Overview 1. Introduction General overview of Simulations , Gene Regulatory Networks and Simulating Gene Regulatory networks 2. Getting started with sismonr Describe how sismonr package works and running the first simulation 3. Scaling up your work Introduction to High Performance Computing 4. Working with job scheduler Introduction to HPC Job Schedulers, Slurm Scheduler & life cycle of a Slurm job, Assessing resource utilisation and profiling 5. Parallel job arrays Introduction to specifications in Parallel Computing, Slurm Job arrays and Exercises on Scaling networks 6. Post-processing Interpreting sismonr output and Visualising the simlulations Supplementary-material.1 Supplementary-material.2","title":"Content"},{"location":"#schedule","text":"Day Time Topic 1 st day: 10am-12:30pm 1. Introduction 12:30pm-1:30pm Lunch break 1:30pm-2:30pm 2. Getting started with sismonr 2:30pm-3.30pm 3. Scaling up your work 4. Working with job scheduler 2 nd day: 10am-12pm 5. Automating large number of tasks 12pm-1pm Lunch break 1pm-2.30pm 5. Post-processing 2.30pm - Question time","title":"Schedule"},{"location":"01_introduction/","text":"1. Introduction \u00b6 Slides are available here . Why simulations are important in research \u00b6 One way to answer a research question is through observations and experiments. A scientist can go in the field or the lab to collect data, and analyse them to answer the question. However, this is not the only way to \"do\" research. The construction of mathematical or statistical models can be an alternative way of testing and generating new hypotheses. It can help us answer questions as \"simple\" as predicting the movement of planets in the Solar system, or as complex as providing a weather forecast. Model : mathematical or statistical representation of a system or phenomenon (cell, ecosystem, solar system, etc). Simulation : Data about the system generated using a mathematical or statistical model. Modelling and simulations are very powerful tools. In particular, they allow us to: explain experimental data, through model fitting and refinement; test hypotheses: without going through expensive and time-consuming experiments. For example, with a model of gene expression in a cell, we can predict the impact of knocking out a gene, without going through all the steps necessary to genetically modify a cell in the lab and then record the expression of its genes; that wouldn't be ethical or even feasible to test in real life: e.g. testing the impact of a drug on human embryo development, understanding the merger of two galaxies; make predictions about new interventions/scenarios: e.g. what would be the consequences of new mutation in a crop, or the impact of different prevention policies on the spreading of a pandemic...; communicate knowledge: e.g. simulations can be use to generate an animation of the formation of a star. Modelling and simulations are used in many fields of science, including for example: Epidemiology : modelling of infectious diseases; for example to predict the spreading of a pandemic and to assess the effects of different prevention measures (see for example a very interesting talk from Dr Rachel Binny on the modelling of the COVID19 response in New Zealand); Ecology : modelling of ecosystems, prediction of species abundance, evaluation of conservation policies; Medicine : construction of organ models, prediction of drug-target binding and drug efficiency; Chemistry , molecular biology : molecules interaction models; Astrophysics : modelling of planet formation, galaxy mergers (see this example ), etc; and many more! In biology, the study of the interactions between biological entities through modelling and simulations is known as Systems Biology ( Macilwain, 2011 ). It is a very interdisciplinary field, building from numerous disciplines (physics, chemistry, biology, computer science, statistics, mathematics, etc). In particular, Systems biologists are interested in understanding the emerging properties of biological systems arising from local interactions between molecular components. This led for example to the construction of a whole-cell computational model ( Kar et al. , 2012 ). In this workshop, we are going to work on one of the topics of Systems Biology, which is simulating the expression of genes involved in a Gene Regulatory Network. What are Gene Regulatory Networks ? \u00b6 An overview of gene expression \u00b6 The instructions necessary to a cell's functioning are encoded in its DNA, which is composed of two anti-parallel chains of nucleotides, intertwined into a double helix. Some portions of this DNA molecule, termed protein-coding genes, contain instructions about the synthesis of proteins, which are important molecular actors fulfilling essential roles in the cell. The complex multi-step process of decoding this information and using it to produce proteins is what we call gene expression. Briefly, gene expression involves: Transcription : the sequence of nucleotides that forms the gene is copied into a \"free-floating\" version called messenger RNA (mRNA), as the result of a complex series of biochemical interactions involving enzymes and other molecules. Translation : the messenger RNA is used as a template to create proteins; each consecutive triplet of nucleotides is translated into a specific amino acid (the building blocks of proteins). The correspondence between triplets of nucleotides and amino acids is known as the genetic code. A sequence of amino acids is thus created from the messenger RNA template, and, once completed, constitutes the synthesised protein. Post-translational modifications : once synthesised, a protein may have to undergo some transformations before attaining its functional state. Such modifications include changes in its conformation (i.e. the way in which the sequence of amino acids is folded in the 3D space), cleavage of a portion of the amino acid sequence, addition of molecular signals to specific amino acids, or binding to other proteins to form protein complexes. Image credit: Fondation Merieux Regulation of gene expression \u00b6 Cells respond and adapt to changes in the environment or other inter- and intra-cellular cues by modulating the expression of their genes, which affects the pool of available proteins. Regulation of gene expression can be achieved by different types of molecular actors: proteins encoded by other genes, regulatory non-coding RNAs (i.e. molecules of RNAs that are not used to produce proteins), or even metabolites. Regulators can control the expression of a given target gene by affecting different steps of the target's expression: Regulation of transcription : this is the most well-known type of gene expression regulation. The regulatory molecule (a protein that regulates transcription is called a transcription factor) controls the production of messenger RNAs from the target gene. Regulation of translation : the regulatory molecule controls the synthesis of proteins from the target mRNAs. Decay regulation : the regulatory molecule affects the rate at which the target mRNAs or proteins are degraded by triggering their decay or protecting them from degradation. Post-translational regulation : the regulator modifies the conformation or sequence of its target proteins, thus affecting the ability of the target protein to perform its cellular function. Regulators that increase the expression of their target are called activators ; those decreasing the expression of their target are called repressors . Typically, the relationship between regulator and target is quite specific, with most regulators controlling the expression of only a few target genes, and most genes being controlled by a small set of regulators. Information about the regulatory relationships between genes can be summarised into graphs, which we call Gene Regulatory Networks (GRN). In a GRN, nodes represent genes, and a directed arrow from gene A to gene B indicates that the products of gene A control the expression of gene B. An example of GRN is given below. From Ma, Sisi, et al. \"De-novo learning of genome-scale regulatory networks in S. cerevisiae.\" Plos one 9.9 (2014): e106479. (available under license CC BY 4.0 ) A given environmental cue typically triggers the activation of a specific regulatory pathway (i.e. a part of the cell-wide GRN), with regulators modulating the expression of their targets in a cascade. Thus, understanding the dynamics of gene expression regulation is key to deciphering how organisms react to certain conditions or environmental triggers. Simulating Gene Regulatory Networks \u00b6 One way to understand the dynamics of GRNs is through simulation; i.e. by simulating the expression over time of genes involved in a GRN. Simulating GRNs allows us to: Test hypotheses about the GRN (by comparing gene expression data collected experimentally to simulations based on our current understanding of the network); predict the response of an organism to a specific condition (e.g. predict the behaviour of a human cell in the presence of a hormone); predict the behaviour of the system in response to modifications of the GRN (e.g. what happens when a critical gene is mutated in a cancer cell?); understand the emerging properties of the system (e.g. a specific pattern of regulation leading to a particular cellular behaviour); To evaluate the performance of statistical tools used to reconstruct GRNs from gene expression data (this is the main reason why sismonr was developed). A model of GRN is generally comprised of 2 or 3 components: A list of genes and of regulatory interactions between the genes (often presented as a graph); A set of rules to convert the regulatory interactions into mathematical or statistical equations; A set of numerical parameters that specify the rate of the different reactions in the model (optional, depends on the type of model used). Classes of GRN models \u00b6 There are many types of models that can be developed to simulate GRNs (see Kalerbach et al. , 2008 ). For example: Logical models : each gene in the GRN is considered as a switch with two states, ON and OFF. Depending on the state (ON or OFF) of a regulator at (discrete) time t and the type of regulation exerted by the regulator on its target (i.e. activative or repressive), the state of the target gene will change (or remain the same) at time t+1; Example of a logical model. a) The GRN modelled. b) The transition rules from one time point to the next for each edge in the GRN. For each possible state of the regulator(s) (white columns), the corresponding state of the target (grey column) at the next time point is shown. 0 represents the OFF state, 1 represents the ON state. c) Simulation of the model: at each time point, the genes are either ON (1) or OFF (0). Example adapted from Karlebach, G., Shamir, R. Modelling and analysis of gene regulatory networks. Nat Rev Mol Cell Biol 9 , 770--780 (2008). https://doi.org/10.1038/nrm2503 . Continuous and deterministic models : ordinary differential expressions (ODEs) are used to describe how the concentrations of the different mRNAs and proteins evolve over time. Regulatory functions are used to describe the change in the production of mRNAs or proteins of a target gene as a function of the concentration of regulator molecules. Example of a continuous and deterministic model, for the same GRN as in the previous example. a) The GRN modelled. b) The system of ODEs used to describe the change in the different genes' concentration over time. The regulatory functions are constructed to match the GRN modelled. c) The trajectories of the model over time (obtained by solving the system of ODEs). The code to reproduce this example is available here . Adapted from Karlebach, G., Shamir, R. Modelling and analysis of gene regulatory networks. Nat Rev Mol Cell Biol 9 , 770--780 (2008). https://doi.org/10.1038/nrm2503 . Discrete and stochastic models : biochemical reactions are used to represent the production, transformation and decay of the molecules (DNA, mRNA and proteins) present in the system of interest. A Stochastic Simulation Algorithm (SSA) is used to predict the evolution of the different molecules' absolute abundance over time, by simulating the occurrence of the different reactions in the system. Example of a discrete and stochastic model. a) The GRN modelled. b) The list of biochemical reactions occuring in the modelled system, with the rate of each reaction indicated above the reaction arrow. c) One simulation obtained with the Stochastic Simulation Algorithm. The code to reproduce this example is available here . Each type of model has its own advantages and drawbacks. A very schematic representation of some of the differences between different classes of GRN models. In this workshop, we will be focusing on the discrete and stochastic class of models. It explicitly accounts for the stochastic noise inherent to biological systems; it is a good option to simulate GRNs as some of the regulatory molecules might be present in small numbers; but the computational burden restricts the simulations to models of GRNs of small size. In a next section, you will learn more about how to simulate expression data from stochastic models using the Stochastic Simulation Algorithm. Tools to simulate GRNs \u00b6 While it is possible to develop \"by hand\" your own model to simulate the expression of genes for a specific GRN, a number of simulators have been developed, each with its own goals, choice of programming language, and modelling assumptions. A few examples are mentioned below. Note that existing tools generally focus on the simulation of transcription regulatory networks, i.e. only regulation of transcription is accounted for. GeneNetWeaver ( Schaffter et al., 2011 ) CaiNet ( Hettich et al., 2021 ) MeSCoT ( Milkevych et al. , 2021 ) Java-implemented software for GRN generation and simulation. Users can either provide their own network graph, or alternatively they can sample a small regulatory network from two possible experimentally derived transcriptional networks (reconstructed respectively from E. coli and S. cerevisiae ). A deterministic or semi-stochastic model is used to represent the expression of genes and transcription regulations between the genes. The model is then used to simulate time-course RNA and proteins normalised concentration. In addition, it is possible to simulate data for different types of network perturbation, e.g. gene knockouts or knockdowns. Matlab/C++-based interactive tool to construct and simulate GRNs. The user can design in the GUI its own transcription regulatory network, which can include external input signal, homo- and heterodimerisation (i.e. the binding of two identical or different proteins to form protein complexes), and enzyme-aided metabolic reactions. A model is then constructed, using a mix of probabilistic and deterministic equations. The simulations are sped-up by simulating individually each gene for short time-steps, then synchronising the different gene expression levels across the entire system. In addition, CaiNet offers a module for the inference of GRN topology and parameters from steady-state gene expression data. Tool for generating and simulating GRNs impacted by genetic mutations and resulting quantitative phenotypes. This is particularly interesting for people working on QTL mapping or GWAS analyses for example. They use stochastic differential equations with time delay to construct the model. In this workshop, we will use the sismonr R package. sismonr generates GRNs that include protein-coding and non-coding genes, and models different types of expression regulation, such as regulation of transcription, translation, RNA or protein decay, and post-translational modifications. sismonr constructs a stochastic model to simulate the abundance of RNAs and proteins in the system over time. A (brief) introduction to the Stochastic Simulation Algorithm \u00b6 In this section, we will see in more details the different components of a stochastic model and how we can use a Stochastic Simulation Algorithm to simulate the model. This is important as it is the type of model and simulation that we are going to work with for the next two days. A stochastic model consists of: a list of (molecular) species present in the system of interest: in our case that would be the different genes, RNAs, proteins, etc. a list of initial abundance for each species in the system, i.e. the number of molecules of each species present in the system at the beginning of the simulation; a list of biochemical reactions that can occur in the system: e.g. substrate 1 (S1) binds with enzyme A (EA) to form a complex (C1A), represented on the form S1 + EA \u2192 C1A a list of constant rates, one per reaction, that represent for a given reaction the probability of one molecule of each reactant colliding and undergoing the reaction in the next time step. Example of a stochastic model. Mathematically, the biochemical reactions are usually represented with a stoichiometry matrix , in which each row corresponds to a species and each column to a reaction. The cells indicate the change in abundance of the different species resulting from one occurrence of the reactions; negative values indicate the reactants of the reactions, while positive values indicate their products. The stoichiometry matrix of the example stochastic model. Notice that in reactions 3 and 4, a species appears as both a reactant and a product, and so is not represented in the stoichiometry matrix. This is because the species is necessary for the reaction, but is not degraded or transformed by the reaction. We can represent the state of the system at a given time point \\(t\\) as a vector of species abundance: \\(\\mathbf{X}(t) = \\left( X_1(t), \\ldots, X_N(t) \\right)\\) , where \\(X_i(t)\\) is the abundance of species \\(i\\) at time \\(t\\) . We already know what the system state is at time point \\(t = 0\\) : this is the initial abundance of the species that we decided on. The goal of the simulation is to simulate the system state over a period of time (say until time point \\(t_{max}\\) ): The system state. In order to do that, we need to simulate the series of occurrence of the reactions. But how do we know which reaction will occur first? and when? We can answer these questions by calculating for each reaction its propensity: the probability of the reaction to \"fire\" (to occur) in the next unit (small) time-step. The propensity of a reaction depends on: The constant rate of the reaction, which is the probability of one molecule of each reactant species to collide and undergo the reaction; and The state of the system at the current time point: more specifically, the abundance of the reactant species. Think about it: a reaction for which one of the reactant is present in very low abundance will have a very low probability of occurring. On the other hand, a reaction for which all reactants are very abundant will likely occur in the next time step. The general formula is, for a reaction \\(i\\) with constant rate \\(r_i\\) and \\(j\\) reactants: \\(p_j(\\mathbf{X}) = r_i \\times \\sum\\limits_{\\text{reactants }j} X_j(t)\\) Which gives, for the reactions in our example: Propensities of some of the reactions. A typical Stochastic Simulation Algorithm will generate the simulation as follows: Initialisation: Start with the initial system state, and set \\(t = 0\\) . Compute the propensity of all reactions, based on the current state of the system; Based on the propensities, randomly generate the time increment \\(\\tau\\) during which the next reaction will occur; Based on the propensities, randomly select which reaction will occur between \\(t\\) and \\(t+ \\tau\\) ; Update time to \\(t + \\tau\\) , update the system state based on which reaction occurred; Repeat steps 1 to 4, until \\(t = t_{max}\\) (the desired end time of the simulation). An example is shown below: Example of one iteration of the SSA. This means that the Stochastic Simulation Algorithm simulates the occurrence of every single reaction in the system. The downside of that is that if several reactions have high propensities, then the interval of time sampled at each iteration of the algorithm will be really small, and so the algorithm will have to go through many iterations before reaching the end of the simulation. This occurs typically when some of the species are present in very high abundance in the system. Illustration of the computational burden of the Stochastic Simulation Algorithm. Left: if reactions all have small propensities, the simulated time intervals are rather large, and the simulation will end quickly. Right: if on the contrary reactions have high propensities, many reactions will occur in short periods of time, and it will take many iterations to reach the end of the simulation. Many variations of this stochastic simulation algorithms have been proposed, to reduce the computational burden of the simulations. Some are exact, i.e. they will simulate the occurrence of each reaction in the system; while other are approximate, i.e. they will try to speed up the calculations at the expense of accuracy. There are many implementations of the different versions of the Stochastic Simulation Algorithm, in the language of your choice: for example the R packages GillespieSSA and adaptivetau , the Python module gillespie , the Julia module BioSimulator.jl , and many (or at least a few) more. The sismonr packages uses under the hood the Julia module BioSimulator.jl to perform the stochastic simulations. You will learn a bit more about how sismonr links R and Julia in the next section.","title":"1. Introduction"},{"location":"01_introduction/#1-introduction","text":"Slides are available here .","title":"1. Introduction"},{"location":"01_introduction/#why-simulations-are-important-in-research","text":"One way to answer a research question is through observations and experiments. A scientist can go in the field or the lab to collect data, and analyse them to answer the question. However, this is not the only way to \"do\" research. The construction of mathematical or statistical models can be an alternative way of testing and generating new hypotheses. It can help us answer questions as \"simple\" as predicting the movement of planets in the Solar system, or as complex as providing a weather forecast. Model : mathematical or statistical representation of a system or phenomenon (cell, ecosystem, solar system, etc). Simulation : Data about the system generated using a mathematical or statistical model. Modelling and simulations are very powerful tools. In particular, they allow us to: explain experimental data, through model fitting and refinement; test hypotheses: without going through expensive and time-consuming experiments. For example, with a model of gene expression in a cell, we can predict the impact of knocking out a gene, without going through all the steps necessary to genetically modify a cell in the lab and then record the expression of its genes; that wouldn't be ethical or even feasible to test in real life: e.g. testing the impact of a drug on human embryo development, understanding the merger of two galaxies; make predictions about new interventions/scenarios: e.g. what would be the consequences of new mutation in a crop, or the impact of different prevention policies on the spreading of a pandemic...; communicate knowledge: e.g. simulations can be use to generate an animation of the formation of a star. Modelling and simulations are used in many fields of science, including for example: Epidemiology : modelling of infectious diseases; for example to predict the spreading of a pandemic and to assess the effects of different prevention measures (see for example a very interesting talk from Dr Rachel Binny on the modelling of the COVID19 response in New Zealand); Ecology : modelling of ecosystems, prediction of species abundance, evaluation of conservation policies; Medicine : construction of organ models, prediction of drug-target binding and drug efficiency; Chemistry , molecular biology : molecules interaction models; Astrophysics : modelling of planet formation, galaxy mergers (see this example ), etc; and many more! In biology, the study of the interactions between biological entities through modelling and simulations is known as Systems Biology ( Macilwain, 2011 ). It is a very interdisciplinary field, building from numerous disciplines (physics, chemistry, biology, computer science, statistics, mathematics, etc). In particular, Systems biologists are interested in understanding the emerging properties of biological systems arising from local interactions between molecular components. This led for example to the construction of a whole-cell computational model ( Kar et al. , 2012 ). In this workshop, we are going to work on one of the topics of Systems Biology, which is simulating the expression of genes involved in a Gene Regulatory Network.","title":"Why simulations are important in research"},{"location":"01_introduction/#what-are-gene-regulatory-networks","text":"","title":"What are Gene Regulatory Networks ?"},{"location":"01_introduction/#an-overview-of-gene-expression","text":"The instructions necessary to a cell's functioning are encoded in its DNA, which is composed of two anti-parallel chains of nucleotides, intertwined into a double helix. Some portions of this DNA molecule, termed protein-coding genes, contain instructions about the synthesis of proteins, which are important molecular actors fulfilling essential roles in the cell. The complex multi-step process of decoding this information and using it to produce proteins is what we call gene expression. Briefly, gene expression involves: Transcription : the sequence of nucleotides that forms the gene is copied into a \"free-floating\" version called messenger RNA (mRNA), as the result of a complex series of biochemical interactions involving enzymes and other molecules. Translation : the messenger RNA is used as a template to create proteins; each consecutive triplet of nucleotides is translated into a specific amino acid (the building blocks of proteins). The correspondence between triplets of nucleotides and amino acids is known as the genetic code. A sequence of amino acids is thus created from the messenger RNA template, and, once completed, constitutes the synthesised protein. Post-translational modifications : once synthesised, a protein may have to undergo some transformations before attaining its functional state. Such modifications include changes in its conformation (i.e. the way in which the sequence of amino acids is folded in the 3D space), cleavage of a portion of the amino acid sequence, addition of molecular signals to specific amino acids, or binding to other proteins to form protein complexes. Image credit: Fondation Merieux","title":"An overview of gene expression"},{"location":"01_introduction/#regulation-of-gene-expression","text":"Cells respond and adapt to changes in the environment or other inter- and intra-cellular cues by modulating the expression of their genes, which affects the pool of available proteins. Regulation of gene expression can be achieved by different types of molecular actors: proteins encoded by other genes, regulatory non-coding RNAs (i.e. molecules of RNAs that are not used to produce proteins), or even metabolites. Regulators can control the expression of a given target gene by affecting different steps of the target's expression: Regulation of transcription : this is the most well-known type of gene expression regulation. The regulatory molecule (a protein that regulates transcription is called a transcription factor) controls the production of messenger RNAs from the target gene. Regulation of translation : the regulatory molecule controls the synthesis of proteins from the target mRNAs. Decay regulation : the regulatory molecule affects the rate at which the target mRNAs or proteins are degraded by triggering their decay or protecting them from degradation. Post-translational regulation : the regulator modifies the conformation or sequence of its target proteins, thus affecting the ability of the target protein to perform its cellular function. Regulators that increase the expression of their target are called activators ; those decreasing the expression of their target are called repressors . Typically, the relationship between regulator and target is quite specific, with most regulators controlling the expression of only a few target genes, and most genes being controlled by a small set of regulators. Information about the regulatory relationships between genes can be summarised into graphs, which we call Gene Regulatory Networks (GRN). In a GRN, nodes represent genes, and a directed arrow from gene A to gene B indicates that the products of gene A control the expression of gene B. An example of GRN is given below. From Ma, Sisi, et al. \"De-novo learning of genome-scale regulatory networks in S. cerevisiae.\" Plos one 9.9 (2014): e106479. (available under license CC BY 4.0 ) A given environmental cue typically triggers the activation of a specific regulatory pathway (i.e. a part of the cell-wide GRN), with regulators modulating the expression of their targets in a cascade. Thus, understanding the dynamics of gene expression regulation is key to deciphering how organisms react to certain conditions or environmental triggers.","title":"Regulation of gene expression"},{"location":"01_introduction/#simulating-gene-regulatory-networks","text":"One way to understand the dynamics of GRNs is through simulation; i.e. by simulating the expression over time of genes involved in a GRN. Simulating GRNs allows us to: Test hypotheses about the GRN (by comparing gene expression data collected experimentally to simulations based on our current understanding of the network); predict the response of an organism to a specific condition (e.g. predict the behaviour of a human cell in the presence of a hormone); predict the behaviour of the system in response to modifications of the GRN (e.g. what happens when a critical gene is mutated in a cancer cell?); understand the emerging properties of the system (e.g. a specific pattern of regulation leading to a particular cellular behaviour); To evaluate the performance of statistical tools used to reconstruct GRNs from gene expression data (this is the main reason why sismonr was developed). A model of GRN is generally comprised of 2 or 3 components: A list of genes and of regulatory interactions between the genes (often presented as a graph); A set of rules to convert the regulatory interactions into mathematical or statistical equations; A set of numerical parameters that specify the rate of the different reactions in the model (optional, depends on the type of model used).","title":"Simulating Gene Regulatory Networks"},{"location":"01_introduction/#classes-of-grn-models","text":"There are many types of models that can be developed to simulate GRNs (see Kalerbach et al. , 2008 ). For example: Logical models : each gene in the GRN is considered as a switch with two states, ON and OFF. Depending on the state (ON or OFF) of a regulator at (discrete) time t and the type of regulation exerted by the regulator on its target (i.e. activative or repressive), the state of the target gene will change (or remain the same) at time t+1; Example of a logical model. a) The GRN modelled. b) The transition rules from one time point to the next for each edge in the GRN. For each possible state of the regulator(s) (white columns), the corresponding state of the target (grey column) at the next time point is shown. 0 represents the OFF state, 1 represents the ON state. c) Simulation of the model: at each time point, the genes are either ON (1) or OFF (0). Example adapted from Karlebach, G., Shamir, R. Modelling and analysis of gene regulatory networks. Nat Rev Mol Cell Biol 9 , 770--780 (2008). https://doi.org/10.1038/nrm2503 . Continuous and deterministic models : ordinary differential expressions (ODEs) are used to describe how the concentrations of the different mRNAs and proteins evolve over time. Regulatory functions are used to describe the change in the production of mRNAs or proteins of a target gene as a function of the concentration of regulator molecules. Example of a continuous and deterministic model, for the same GRN as in the previous example. a) The GRN modelled. b) The system of ODEs used to describe the change in the different genes' concentration over time. The regulatory functions are constructed to match the GRN modelled. c) The trajectories of the model over time (obtained by solving the system of ODEs). The code to reproduce this example is available here . Adapted from Karlebach, G., Shamir, R. Modelling and analysis of gene regulatory networks. Nat Rev Mol Cell Biol 9 , 770--780 (2008). https://doi.org/10.1038/nrm2503 . Discrete and stochastic models : biochemical reactions are used to represent the production, transformation and decay of the molecules (DNA, mRNA and proteins) present in the system of interest. A Stochastic Simulation Algorithm (SSA) is used to predict the evolution of the different molecules' absolute abundance over time, by simulating the occurrence of the different reactions in the system. Example of a discrete and stochastic model. a) The GRN modelled. b) The list of biochemical reactions occuring in the modelled system, with the rate of each reaction indicated above the reaction arrow. c) One simulation obtained with the Stochastic Simulation Algorithm. The code to reproduce this example is available here . Each type of model has its own advantages and drawbacks. A very schematic representation of some of the differences between different classes of GRN models. In this workshop, we will be focusing on the discrete and stochastic class of models. It explicitly accounts for the stochastic noise inherent to biological systems; it is a good option to simulate GRNs as some of the regulatory molecules might be present in small numbers; but the computational burden restricts the simulations to models of GRNs of small size. In a next section, you will learn more about how to simulate expression data from stochastic models using the Stochastic Simulation Algorithm.","title":"Classes of GRN models"},{"location":"01_introduction/#tools-to-simulate-grns","text":"While it is possible to develop \"by hand\" your own model to simulate the expression of genes for a specific GRN, a number of simulators have been developed, each with its own goals, choice of programming language, and modelling assumptions. A few examples are mentioned below. Note that existing tools generally focus on the simulation of transcription regulatory networks, i.e. only regulation of transcription is accounted for. GeneNetWeaver ( Schaffter et al., 2011 ) CaiNet ( Hettich et al., 2021 ) MeSCoT ( Milkevych et al. , 2021 ) Java-implemented software for GRN generation and simulation. Users can either provide their own network graph, or alternatively they can sample a small regulatory network from two possible experimentally derived transcriptional networks (reconstructed respectively from E. coli and S. cerevisiae ). A deterministic or semi-stochastic model is used to represent the expression of genes and transcription regulations between the genes. The model is then used to simulate time-course RNA and proteins normalised concentration. In addition, it is possible to simulate data for different types of network perturbation, e.g. gene knockouts or knockdowns. Matlab/C++-based interactive tool to construct and simulate GRNs. The user can design in the GUI its own transcription regulatory network, which can include external input signal, homo- and heterodimerisation (i.e. the binding of two identical or different proteins to form protein complexes), and enzyme-aided metabolic reactions. A model is then constructed, using a mix of probabilistic and deterministic equations. The simulations are sped-up by simulating individually each gene for short time-steps, then synchronising the different gene expression levels across the entire system. In addition, CaiNet offers a module for the inference of GRN topology and parameters from steady-state gene expression data. Tool for generating and simulating GRNs impacted by genetic mutations and resulting quantitative phenotypes. This is particularly interesting for people working on QTL mapping or GWAS analyses for example. They use stochastic differential equations with time delay to construct the model. In this workshop, we will use the sismonr R package. sismonr generates GRNs that include protein-coding and non-coding genes, and models different types of expression regulation, such as regulation of transcription, translation, RNA or protein decay, and post-translational modifications. sismonr constructs a stochastic model to simulate the abundance of RNAs and proteins in the system over time.","title":"Tools to simulate GRNs"},{"location":"01_introduction/#a-brief-introduction-to-the-stochastic-simulation-algorithm","text":"In this section, we will see in more details the different components of a stochastic model and how we can use a Stochastic Simulation Algorithm to simulate the model. This is important as it is the type of model and simulation that we are going to work with for the next two days. A stochastic model consists of: a list of (molecular) species present in the system of interest: in our case that would be the different genes, RNAs, proteins, etc. a list of initial abundance for each species in the system, i.e. the number of molecules of each species present in the system at the beginning of the simulation; a list of biochemical reactions that can occur in the system: e.g. substrate 1 (S1) binds with enzyme A (EA) to form a complex (C1A), represented on the form S1 + EA \u2192 C1A a list of constant rates, one per reaction, that represent for a given reaction the probability of one molecule of each reactant colliding and undergoing the reaction in the next time step. Example of a stochastic model. Mathematically, the biochemical reactions are usually represented with a stoichiometry matrix , in which each row corresponds to a species and each column to a reaction. The cells indicate the change in abundance of the different species resulting from one occurrence of the reactions; negative values indicate the reactants of the reactions, while positive values indicate their products. The stoichiometry matrix of the example stochastic model. Notice that in reactions 3 and 4, a species appears as both a reactant and a product, and so is not represented in the stoichiometry matrix. This is because the species is necessary for the reaction, but is not degraded or transformed by the reaction. We can represent the state of the system at a given time point \\(t\\) as a vector of species abundance: \\(\\mathbf{X}(t) = \\left( X_1(t), \\ldots, X_N(t) \\right)\\) , where \\(X_i(t)\\) is the abundance of species \\(i\\) at time \\(t\\) . We already know what the system state is at time point \\(t = 0\\) : this is the initial abundance of the species that we decided on. The goal of the simulation is to simulate the system state over a period of time (say until time point \\(t_{max}\\) ): The system state. In order to do that, we need to simulate the series of occurrence of the reactions. But how do we know which reaction will occur first? and when? We can answer these questions by calculating for each reaction its propensity: the probability of the reaction to \"fire\" (to occur) in the next unit (small) time-step. The propensity of a reaction depends on: The constant rate of the reaction, which is the probability of one molecule of each reactant species to collide and undergo the reaction; and The state of the system at the current time point: more specifically, the abundance of the reactant species. Think about it: a reaction for which one of the reactant is present in very low abundance will have a very low probability of occurring. On the other hand, a reaction for which all reactants are very abundant will likely occur in the next time step. The general formula is, for a reaction \\(i\\) with constant rate \\(r_i\\) and \\(j\\) reactants: \\(p_j(\\mathbf{X}) = r_i \\times \\sum\\limits_{\\text{reactants }j} X_j(t)\\) Which gives, for the reactions in our example: Propensities of some of the reactions. A typical Stochastic Simulation Algorithm will generate the simulation as follows: Initialisation: Start with the initial system state, and set \\(t = 0\\) . Compute the propensity of all reactions, based on the current state of the system; Based on the propensities, randomly generate the time increment \\(\\tau\\) during which the next reaction will occur; Based on the propensities, randomly select which reaction will occur between \\(t\\) and \\(t+ \\tau\\) ; Update time to \\(t + \\tau\\) , update the system state based on which reaction occurred; Repeat steps 1 to 4, until \\(t = t_{max}\\) (the desired end time of the simulation). An example is shown below: Example of one iteration of the SSA. This means that the Stochastic Simulation Algorithm simulates the occurrence of every single reaction in the system. The downside of that is that if several reactions have high propensities, then the interval of time sampled at each iteration of the algorithm will be really small, and so the algorithm will have to go through many iterations before reaching the end of the simulation. This occurs typically when some of the species are present in very high abundance in the system. Illustration of the computational burden of the Stochastic Simulation Algorithm. Left: if reactions all have small propensities, the simulated time intervals are rather large, and the simulation will end quickly. Right: if on the contrary reactions have high propensities, many reactions will occur in short periods of time, and it will take many iterations to reach the end of the simulation. Many variations of this stochastic simulation algorithms have been proposed, to reduce the computational burden of the simulations. Some are exact, i.e. they will simulate the occurrence of each reaction in the system; while other are approximate, i.e. they will try to speed up the calculations at the expense of accuracy. There are many implementations of the different versions of the Stochastic Simulation Algorithm, in the language of your choice: for example the R packages GillespieSSA and adaptivetau , the Python module gillespie , the Julia module BioSimulator.jl , and many (or at least a few) more. The sismonr packages uses under the hood the Julia module BioSimulator.jl to perform the stochastic simulations. You will learn a bit more about how sismonr links R and Julia in the next section.","title":"A (brief) introduction to the Stochastic Simulation Algorithm"},{"location":"02_getting_started_sismonr/","text":"2. Getting started with sismonr \u00b6 Introduction to the sismonr package \u00b6 The sismonr package was developed for the purpose of generating benchmark datasets, in order to assess the performance of statistical methods that reconstruct GRNs from experimental datasets such as RNAseq data. Therefore, sismonr allows the user to generate random GRNs that mimic some of the properties of biological regulatory networks. Alternatively, the user can construct their own regulatory network. sismonr can supports different types of regulation (e.g. transcription, translation or decay regulation). Genes can code for proteins or for non-coding regulatory RNAs; gene products can form regulatory complexes. One unique features of sismonr is that it allows the user to define the ploidy of the system, i.e. how many copies of each gene are present in the system. Lastly, sismonr simulates the expression of the genes in a GRN for different in silico individuals, that carry different versions (or alleles) of the genes present in the GRN (think of it as simulating gene expression from different subjects). This is quite useful to simulate gene expression under different scenarios such as gene knock-outs for example. If you are interested, a full tutorial is available here . One particularity of sismonr is that it is available as an R package; but internally it uses the programming language Julia to speed up some of the calculations. No worries though, you don't need to know anything about Julia to use sismonr! How sismonr links R and Julia \u00b6 Before we get into the fun part, which is getting to play with the sismonr package, it is important to know a little bit about sismonr works. More specifically, we will now briefly cover how sismonr uses Julia to run the simulations and other computations. This will be important when scaling-up our work from a local machine to a HPC environment. sismonr handles communications between R and Julia via the XRJulia R package. The first time you use a function from the sismonr package that requires Julia, sismonr (via XRJulia functions) opens a new julia process on your computer, and sets up a socket connection between the R session and the new julia process. By default, this connection is set up on a random port, but there are ways to decide on the port to use: by executing, at the start of your R session, the following command: XRJulia :: newJuliaEvaluator ( port = as.integer ( 456 )) you are creating a new Julia process and the socket connection between the R session and the Julia process will use port 456. We won't need to use this for now, but you will find it useful later on :) Once the Julia process is started, whenever sismonr needs to run some computations in Julia, the necessary R objects are sent to the Julia process, which executes the required commands. Once done, the Julia process sends back the results to the R session. This way, the user doesn't have to interact with Julia at all. A very schematic representation of how sismonr uses the XRJulia package to run simulations in Julia from a R session. This is why, if you decide to use sismonr on your own computer, you will have to install Julia first, and make sure that R can find the Julia executable (for example by adding Julia to the PATH, which is done for you when installing Julia). Practice time! \u00b6 For this next section, you will need to login to NeSI Mahuika Jupyter and to open a sismonr Jupyter notebook. See here for instructions on how to login to NeSI Mahuika Jupyter and how to open a sismonr Jupyter kernel. Follow instructions up to S.2 2 (Guide Jupyter file explorer (left panel) to above working directory) included. Before opening a Jupyter Notebook, we will create a folder to save our work from this section: Now we can open a sismonr Jupyter Notebook: Before getting started, here are some abbreviations that are often used within sismonr: Abbreviations Meaning TC Transcription TL Translation RD RNA decay PD Protein decay PTM Post-translational modification PC Protein-coding NC Noncoding R RNA P Protein Pm Modified protein C Regulatory complex Generating a random GRN \u00b6 We will start by generating a small random GRN with sismonr, using the function createInSilicoSystem() . library ( sismonr ) set.seed ( 12 ) # important for reproducibility of \"random\" results in R! small_grn <- createInSilicoSystem ( G = 10 , # number of genes in the GRN PC.p = 1 , # proportion of genes that are protein-coding ploidy = 2 ) # ploidy of the system Note that the first time you run a sismonr command, you might have to wait a few seconds, as sismonr needs to open a new Julia process on your computer to execute some of the internal commands (such as the generation of a random GRN). You can visualise the GRN you just created with the following command (the resulting graph is interactive, try to hover over nodes or edges with your mouse, move nodes or click on nodes): plotGRN ( small_grn ) visNetwork {\"x\":{\"nodes\":{\"id\":[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"CTC1\"],\"type\":[\"Gene\",\"Gene\",\"Gene\",\"Gene\",\"Gene\",\"Gene\",\"Gene\",\"Gene\",\"Gene\",\"Gene\",\"Complex\"],\"coding\":[\"PC\",\"PC\",\"PC\",\"PC\",\"PC\",\"PC\",\"PC\",\"PC\",\"PC\",\"PC\",\"Complex\"],\"targetReaction\":[\"TC\",\"PD\",\"TC\",\"TC\",\"TC\",\"TL\",\"TL\",\"TL\",\"TL\",\"TC\",\"TC\"],\"label\":[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"CTC1\"],\"shape\":[\"ellipse\",\"ellipse\",\"ellipse\",\"ellipse\",\"ellipse\",\"ellipse\",\"ellipse\",\"ellipse\",\"ellipse\",\"ellipse\",\"box\"],\"color\":[\"#FF834A\",\"#7DCCFF\",\"#FF834A\",\"#FF834A\",\"#FF834A\",\"#579BDB\",\"#579BDB\",\"#579BDB\",\"#579BDB\",\"#FF834A\",\"#FF834A\"],\"borderWidth\":[0,0,0,0,0,0,0,0,0,0,2],\"group\":[\"1\",\"1\",\"1\",\"1\",\"1\",\"1\",\"1\",\"1\",\"1\",\"1\",\"1\"],\"title\":[\"1 (id: 1)<br>Protein-coding gene<br>Transcription regulator\",\"2 (id: 2)<br>Protein-coding gene<br>Regulator of protein decay\",\"3 (id: 3)<br>Protein-coding gene<br>Transcription regulator\",\"4 (id: 4)<br>Protein-coding gene<br>Transcription regulator\",\"5 (id: 5)<br>Protein-coding gene<br>Transcription regulator\",\"6 (id: 6)<br>Protein-coding gene<br>Translation regulator\",\"7 (id: 7)<br>Protein-coding gene<br>Translation regulator\",\"8 (id: 8)<br>Protein-coding gene<br>Translation regulator\",\"9 (id: 9)<br>Protein-coding gene<br>Translation regulator\",\"10 (id: 10)<br>Protein-coding gene<br>Transcription regulator\",\"CTC1 (id: CTC1)<br>Regulatory complex<br>Transcription regulator<br>Composed of: 10, 1\"]},\"edges\":{\"from\":[\"4\",\"5\",\"3\",\"1\",\"3\",\"5\",\"CTC1\",\"7\",\"9\",\"6\",\"8\",\"2\",\"10\",\"1\"],\"to\":[\"10\",\"10\",\"2\",\"3\",\"3\",\"5\",\"9\",\"2\",\"4\",\"7\",\"7\",\"1\",\"CTC1\",\"CTC1\"],\"type\":[\"Regulation\",\"Regulation\",\"Regulation\",\"Regulation\",\"Regulation\",\"Regulation\",\"Regulation\",\"Regulation\",\"Regulation\",\"Regulation\",\"Regulation\",\"Regulation\",\"Binding\",\"Binding\"],\"targetReaction\":[\"TC\",\"TC\",\"TC\",\"TC\",\"TC\",\"TC\",\"TC\",\"TL\",\"TL\",\"TL\",\"TL\",\"PD\",\"none\",\"none\"],\"sign\":[\"1\",\"-1\",\"-1\",\"1\",\"1\",\"1\",\"-1\",\"1\",\"-1\",\"-1\",\"-1\",\"1\",\"none\",\"none\"],\"arrows\":[\"to\",\"to\",\"to\",\"to\",\"to\",\"to\",\"to\",\"to\",\"to\",\"to\",\"to\",\"to\",null,null],\"color\":[null,null,null,null,null,null,null,null,null,null,null,null,\"#999999\",\"#999999\"],\"dashes\":[false,true,true,false,false,false,true,false,true,true,true,false,null,null],\"edge_meaning\":[\" activates the transcription of \",\" represses the transcription of \",\" represses the transcription of \",\" activates the transcription of \",\" activates the transcription of \",\" activates the transcription of \",\" represses the transcription of \",\" activates the translation of \",\" represses the translation of \",\" represses the translation of \",\" represses the translation of \",\" activates the protein decay of \",\" is part of complex \",\" is part of complex \"],\"title\":[\"4 activates the transcription of 10\",\"5 represses the transcription of 10\",\"3 represses the transcription of 2\",\"1 activates the transcription of 3\",\"3 activates the transcription of 3\",\"5 activates the transcription of 5\",\"CTC1 represses the transcription of 9\",\"7 activates the translation of 2\",\"9 represses the translation of 4\",\"6 represses the translation of 7\",\"8 represses the translation of 7\",\"2 activates the protein decay of 1\",\"10 is part of complex CTC1\",\"1 is part of complex CTC1\"]},\"nodesToDataframe\":true,\"edgesToDataframe\":true,\"options\":{\"width\":\"100%\",\"height\":\"100%\",\"nodes\":{\"shape\":\"dot\",\"size\":20,\"physics\":false},\"manipulation\":{\"enabled\":false},\"layout\":{\"randomSeed\":123,\"improvedLayout\":true},\"physics\":{\"timestep\":1}},\"groups\":[\"1\"],\"width\":\"800px\",\"height\":null,\"idselection\":{\"enabled\":false,\"style\":\"width: 150px; height: 26px\",\"useLabels\":true,\"main\":\"Select by id\"},\"byselection\":{\"enabled\":false,\"style\":\"width: 150px; height: 26px\",\"multiple\":false,\"hideColor\":\"rgba(200,200,200,0.5)\",\"highlight\":false},\"main\":null,\"submain\":null,\"footer\":null,\"background\":\"rgba(0, 0, 0, 0)\",\"highlight\":{\"enabled\":true,\"hoverNearest\":false,\"degree\":1,\"algorithm\":\"all\",\"hideColor\":\"rgba(200,200,200,0.5)\",\"labelOnly\":true},\"collapse\":{\"enabled\":false,\"fit\":false,\"resetHighlight\":true,\"clusterOptions\":null,\"keepCoord\":true,\"labelSuffix\":\"(cluster)\"},\"legend\":{\"width\":0.2,\"useGroups\":false,\"position\":\"left\",\"ncol\":1,\"stepX\":100,\"stepY\":80,\"zoom\":true,\"edges\":{\"label\":[\"\\n\\nActivation\",\"\\n\\nRepression\",\"\\n\\n Part of complex\"],\"color\":[\"black\",\"black\",\"#999999\"],\"arrows\":[\"to\",\"to\",null],\"dashes\":[null,true,null]},\"edgesToDataframe\":true,\"nodes\":{\"label\":[\"Protein-coding gene\",\"Non-coding gene\",\"Regulatory complex\",\"Transcription regulator\",\"Translation regulator\",\"Regulator of RNA decay\",\"Regulator of protein decay\",\"Regulator of post-\\ntranslational modification\"],\"shape\":[\"ellipse\",\"diamond\",\"box\",\"diamond\",\"diamond\",\"diamond\",\"diamond\",\"diamond\"],\"color\":[\"#F2F2F2\",\"#F2F2F2\",\"#F2F2F2\",\"#FF834A\",\"#579BDB\",\"#FFB746\",\"#7DCCFF\",\"#4BC095\"],\"borderWidth\":[0,0,2,0,0,0,0,0]},\"nodesToDataframe\":true,\"main\":{\"text\":\"Legend\",\"style\":\"font-family:Georgia, Times New Roman, Times, serif;font-weight:bold;font-size:14px;text-align:center;\"}}},\"evals\":[],\"jsHooks\":[]} {\"viewer\":{\"width\":\"800px\",\"height\":350,\"padding\":0,\"fill\":false},\"browser\":{\"width\":\"800px\",\"height\":500,\"padding\":0,\"fill\":false}} Alternatively, you can get a list of the genes and regulatory relationships in the GRN through: getGenes ( small_grn ) id coding TargetReaction PTMform ActiveForm TCrate TLrate RDrate PDrate 1 1 PC TC 0 P1 0.0010706485 0.115208445 0.0006563273 0.0003594616 2 2 PC PD 0 P2 0.0007063012 1.096787613 0.0002886745 0.0008614784 3 3 PC TC 0 P3 0.0010690560 0.016254643 0.0004565128 0.0002589524 4 4 PC TC 0 P4 0.0020231676 0.006923935 0.0008362586 0.0011683879 5 5 PC TC 0 P5 0.0017721606 0.021329358 0.0011665348 0.0004787676 6 6 PC TL 0 P6 0.0011366749 0.017786830 0.0008228596 0.0002831087 7 7 PC TL 0 P7 0.0052234381 0.060540559 0.0007973883 0.0007609887 8 8 PC TL 0 P8 0.0026365016 0.017948936 0.0006848954 0.0003388916 9 9 PC TL 0 P9 0.0030150020 0.140724990 0.0006802817 0.0002328448 10 10 PC TC 0 P10 0.0015819471 0.007701612 0.0006157945 0.0005439300 and: getEdges ( small_grn ) from to TargetReaction RegSign RegBy 1 4 10 TC 1 PC 2 5 10 TC -1 PC 3 3 2 TC -1 PC 4 1 3 TC 1 PC 5 3 3 TC 1 PC 6 5 5 TC 1 PC 7 CTC1 9 TC -1 C 8 7 2 TL 1 PC 9 9 4 TL -1 PC 10 6 7 TL -1 PC 11 8 7 TL -1 PC 12 2 1 PD 1 PC Note that you can modify the properties of your system by changing the values in these data-frames. The createInSilicoSystem function accepts many arguments allowing the user to customise the GRN to be created. You can find a list of these by tying: ? insilicosystemargs For example, you can generate a network of 5 genes with only protein-coding genes that are regulators of transcription with: set.seed ( 45 ) another_grn <- createInSilicoSystem ( G = 5 , PC.p = 1 , PC.TC.p = 1 ) # all protein-coding genes are # regulators of transcription Modifying a GRN \u00b6 In addition, you can add genes in your GRN, and add or remove regulatory relationships between genes (currently it is not possible to remove genes, this option will be added in the future). When adding a gene, you can specify its kinetic parameters, e.g. its transcription rate (in RNA/sec), RNA decay rate, etc. small_grn2 <- addGene ( small_grn , coding = \"PC\" , TCrate = 0.01 , RDrate = 0.005 ) Same thing when adding an edge to the GRN: you can decide if the regulation is activative or repressive, and the different rates of the regulation: small_grn3 <- addEdge ( small_grn2 , regID = 11 , tarID = 8 , regsign = \"1\" ) Simulating genetically diverse in silico individuals \u00b6 Two individuals from a same species are not genetically identical. They carry the different versions (called alleles) of the same genes. Genetic mutations in or around a gene influence the dynamics of gene expression. To account for that, sismonr does not directly simulate the expression of genes in a GRN, but simulates the expression of the genes for different in silico individuals. More details can be found in the sismonr tutorial . Once you've created a GRN with sismonr, you can generate in silico individuals with the createInSilicoPopulation function. For example, let us generate 3 random in silico individuals; we'll assume that for each gene, they can carry one of 2 possible alleles (this can be customised further but we won't go into details). set.seed ( 123 ) small_pop <- createInSilicoPopulation ( 3 , # number of individuals small_grn , # our GRN ngenevariants = 2 ) # how many alleles exist per gene We can visualise the difference between the individuals via: plotMutations ( small_pop , small_grn , nGenesPerRow = 5 ) A plot representing, for each in silico individual (rows) and each gene (columns), the effect (colour) of genetic mutations on different aspects of the gene's expression (x-axis) for each allele (y-axis) carried by the individual. For noncoding genes, some QTL effect coefficients are not relevant (the ones related to protein or translation) and are represented in gray. For example, in silico individual Ind1 has no mutation on any of its copies of gene 1. It carries two different alleles of gene 2. Tip : to increase the size of the figure generated in a Jupyter notebook cell, add the following command at the top of the cell: options ( repr.plot.width = 18 , repr.plot.height = 12 ) Generating a stochastic model with the sismonr package \u00b6 As mentioned previously, simulators rely on a set of rules to convert the GRN into a mathematical or statistical model that can be used to simulate gene expression over time. This set of rules will depend on the type of model we want to construct (boolean, deterministic, etc). In the case of a stochastic model, we must decide how to transform a graph representing regulatory interactions between genes into a set of biochemical reactions. There is no correct answer. The modelling decisions will influence the precision of the model, with biological accuracy balancing computational efficiency. As an example, the sismonr uses the following rules: This is how sismonr models different type of expression regulation. Each arrow \\(i \\rightarrow j\\) in the GRN is transformed into a set of biochemical reactions with associated rates, as presented. For example, the following small GRN: A small GRN with 3 genes; gene 1 activates the transcription of gene 2; gene 2 activates the transcription of gene 3; and gene 3 represses the transcription of gene 1. is transformed into the following set of reactions: ## Binding/unbinding of regulators to/from their target's DNA Pr2reg1F + P1 --> Pr2reg1B Pr2reg1B --> Pr2reg1F + P1 Pr3reg2F + P2 --> Pr3reg2B Pr3reg2B --> Pr3reg2F + P2 Pr1reg3F + P3 --> Pr1reg3B Pr1reg3B --> Pr1reg3F + P3 ## Basal and regulated transcription Pr1reg3F --> Pr1reg3F + R1 Pr2reg1F --> Pr2reg1F + R2 Pr2reg1B --> Pr2reg1B + R2 Pr3reg2F --> Pr3reg2F + R3 Pr3reg2B --> Pr3reg2B + R3 ## Translation R1 --> R1 + P1 R2 --> R2 + P2 R3 --> R3 + P3 ## RNA decay R1 --> 0 R2 --> 0 R3 --> 0 ## Protein decay (including those bound to DNA) P1 --> 0 Pr2reg1B --> Pr2reg1F P2 --> 0 Pr3reg2B --> Pr3reg2F P3 --> 0 Pr1reg3B --> Pr1reg3F where : PrXregY represents the DNA region of gene X where regulator Y binds; PrXregYF represents the region with no bound regulator (free), and PrXregYB represents the region with a regulator bound to it RX represents the RNA produced by gene X; PX represents the protein produced by gene X. (It's actually a bit more complicated than that, as sismonr accounts for the ploidy of the system, i.e. how many copies of each gene are present, and tracks each copy separately). If you are interested, the code to reproduce this example is available here . One crucial thing to understand is that a reaction in a stochastic system is a simplified representation of a set of true biochemical reactions happening in the biological system. For example, in the example above, the reaction R1 --> R1 + P1 , which represents the translation of gene 1, ignores the fact that the translation of a messenger RNA is a very complex process involving many steps and molecular actors. Decisions must also be made about the rate of the different reactions, as well as the initial abundance of the molecules when the simulation starts. This is again a very complex step in the creation of a model, as it is quite arduous to precisely estimate the rate of different biochemical reactions in vivo . When constructing a stochastic model for a given GRN, sismonr computes for each reaction in the model a constant rate (i.e. the probability of one molecule of each reactant to collide and undergo the reaction in one unit of time), which depends on the properties of the genes (e.g. transcription rate) and of the GRN (e.g. strength of regulation). These rates will be influenced by \"genetic mutations\" that differentiate the in silico individuals modelled by sismonr. Here are the rates of each reaction for two genetically different in silico individuals: reaction rate_Ind1 rate_Ind2 Pr2reg1F + P1 --> Pr2reg1B 5.89e-06 5.27e-06 Pr2reg1B --> Pr2reg1F + P1 2.45e-03 2.45e-03 Pr3reg2F + P2 --> Pr3reg2B 3.46e-05 3.32e-05 Pr3reg2B --> Pr3reg2F + P2 2.86e-03 2.86e-03 Pr1reg3F + P3 --> Pr1reg3B 1.36e-06 1.25e-06 Pr1reg3B --> Pr1reg3F + P3 9.84e-04 9.84e-04 Pr1reg3F --> Pr1reg3F + R1 6.54e-04 6.54e-04 Pr2reg1F --> Pr2reg1F + R2 1.13e-03 1.22e-03 Pr2reg1B --> Pr2reg1B + R2 7.75e-03 8.39e-03 Pr3reg2F --> Pr3reg2F + R3 1.63e-03 1.54e-03 Pr3reg2B --> Pr3reg2B + R3 8.28e-03 7.84e-03 R1 --> R1 + P1 1.02e-01 1.02e-01 R2 --> R2 + P2 8.88e-03 8.69e-03 R3 --> R3 + P3 3.09e-01 3.22e-01 R1 --> 0 6.20e-04 6.20e-04 R2 --> 0 6.48e-04 5.78e-04 R3 --> 0 4.55e-04 4.57e-04 P1 --> 0 1.95e-04 1.95e-04 Pr2reg1B --> Pr2reg1F 1.95e-04 1.95e-04 P2 --> 0 1.23e-04 1.13e-04 Pr3reg2B --> Pr3reg2F 1.23e-04 1.13e-04 P3 --> 0 1.02e-03 1.05e-03 Pr1reg3B --> Pr1reg3F 1.02e-03 1.05e-03 The list of reactions and associated rates is what sismonr uses to simulate the expression of the genes over time for each in silico individual. Tip : The getReactions() function from sismonr allows you to see the list of biochemical reactions and associated rates for a GRN. There are two ways to use the function. Providing only the GRN object as an input to the function, as follows: getReactions ( small_grn ) will return a data-frame with the list of biochemical reactions, their name and the formula used by sismonr to compute their constant rate. If you also provide the in silico inviduals as an input to the function, like so: getReactions ( small_grn , small_pop ) the resulting data-frame will contain, in addition to the columns previously described, one column for each in silico individual giving the constant rate of the reactions for this individual. Workshop's challenge: modelling the anthocyanin biosynthesis regulation pathway in eudicots \u00b6 For this workshop, we will work on a model for the anthocyanin biosynthesis regulation pathway in eudicots . Anthocyanins are pgiments providing colouration to plants, flowers and fruits. This model was developed (mainly) based on the following sources: Albert, Nick W., et al. \"A conserved network of transcriptional activators and repressors regulates anthocyanin pigmentation in eudicots.\" The Plant Cell 26.3 (2014): 962-980. https://doi.org/10.1105/tpc.113.122069 Liu, Ying, et al. \"Anthocyanin biosynthesis and degradation mechanisms in Solanaceous vegetables: a review.\" Frontiers in Chemistry 6 (2018): 52. https://doi.org/10.3389/fchem.2018.00052 Xu, Wenjia, Christian Dubos, and Lo\u00efc Lepiniec. \"Transcriptional control of flavonoid biosynthesis by MYB\u2013bHLH\u2013WDR complexes.\" Trends in plant science 20.3 (2015): 176-185. https://doi.org/10.1016/j.tplants.2014.12.001 Baudry, Antoine, et al. \"TT2, TT8, and TTG1 synergistically specify the expression of BANYULS and proanthocyanidin biosynthesis in Arabidopsis thaliana.\" The Plant Journal 39.3 (2004): 366-380. https://doi.org/10.1111/j.1365-313X.2004.02138.x An animation of the GRN is presented below: \ud83e\udd13 Schema of the model of the anthocyanin biosynthesis regulation pathway. A static image of the model can be found here . The GRN starts with 3 protein-genes, MYB , bHLH1 and WDR . While bHLH1 and WDR are constitutively expressed (i.e. constantly produce proteins), MYB is only expressed in response to certain inductive conditions such as the presence of light. Their proteins assemble into a regulatory complex (termed MBW1), which activates the transcription of the bHLH2 gene. The synthesised bHLH2 proteins form a second regulatory complex with the MYB and WDR proteins (termed MBW2). This complex then activates the transcription of downstream genes encoding for enzymes involved in the anthocyanin biosynthesis pathway. The presence of these enzymes result in the production of anthocyanin. Here we use the DFR gene as a representative example of MBW2's targets. We will assume that the abundance of DFR proteins acts as a proxy for the production of anthocyanins. In addition, the MBW2 complex also activates the transcription of two repressors genes, MYBrep and R3-MYB , which form a negative feedback loop in the GRN. Both genes repress the activity of the network through different means. The MYBrep proteins bind the MBW2 complex (this new complex is termed MBWr), which becomes a repressor complex. It will inhibit the transcription of bHLH2 , which in turn reduces the expression of the downstream enzymes and thus modulates the production of anthocyanin. It also directly inhibits the expression of the MBW2 targets, including MYBrep and DFR . The R3-MYB exert instead a passive repression on the system, by binding to bHLH1 and bHLH2 proteins, thus reducing the number of available bHLH1 and bHLH2 proteins in the system. In consequence, this reduces the number of MBW1 and MBW2 complexes in the system and in turn reduces the activity of the network. The goal of this workshop will be to simulate the expression of the different genes in the pathway over a period of 1,200 seconds (20 minutes) after induction of the MYB gene. We will simulate the GRN for two different in silico plants: A wild type plant: the different kinetic parameters are set to the default values; A mutant plant in which the MYBrep gene is overexpressed: the transcription rate of the gene is increased 50-fold. This can be achieved experimentally by transforming a plant, in order to modify the promoter of the target gene. Because the simulations are stochastic, it is better to simulate the GRN a large number of times in order to obtain a good overview of the system behaviour. We will aim to produce 2,000 simulations. In order to save time, the GRN and the in silico plants have already been generated with sismonr. The R script used to generate it can be found here . The sismonr objects representing the anthocyanin biosynthesis regulation network and the in silico plants are saved in the following .RData file: /nesi/project/nesi02659/sismonr_workshop/sismonr_anthocyanin_system.RData Alternatively, it can be downloaded here . You will start by creating a copy of this object in your working directory, for easier access. In a terminal, type: $ cp /nesi/project/nesi02659/sismonr_workshop/sismonr_anthocyanin_system.RData ~/sism_2021/ You can check that it worked with: $ ls -l ~/sism_2021/ total 0 -r--r-----+ 1 oangelin nesi02659 5417 Nov 22 17 :05 sismonr_anthocyanin_system.RData Running a first simulation (interactive) \u00b6 You will start by running one simulation on your local machine. This is the first thing to do if you are planning to run simulations on NeSI: first, make sure your code actually works! For this workshop, a jupyter kernel will act as your local machine. Start by opening a sismonr kernel (see the instructions here ). We will first load the sismonr package, and the model and in silico plants we want to simulate. Create a new sismonr Jupyter Notebook and add: library ( sismonr ) load ( \"~/sism_2021/sismonr_anthocyanin_system.RData\" ) This sismonr_anthocyanin_system.RData file contains the following R objects: colsystem : the in silico GRN constructed with sismonr; plants : the in silico population of individuals corresponding to the GRN; id2names : character vector that links the ID of the genes and regulatory complexes in the colsystem GRN to their name; colours : character vector that assigns each gene and regulatory complex its own colour (for plotting purposes). Feel free to inspect the different aspects of the model (using for example plotGRN(colsystem) , plotMutations(plants, colsystem) or getReactions(colsystem, plants) ). We can run one simulation for each of the two in silico plants via the command: set.seed ( 123 ) sim <- simulateInSilicoSystem ( colsystem , plants , simtime = 1200 , ntrials = 1 ) Where simtime is the time (in seconds) for which we want to simulate the expression of the genes; ntrials corresponds to the number of times we want to repeat the simulation for each in silico individual. This should take around six minutes to complete. Once this is done, you can visualise the result with the plotSimulation function. There is the option to display only a certain subset of molecules (we'll ignore all intermediary complexes so as to not clutter the graph), and to provide custom colours and labels for the different components: plotSimulation ( sim $ Simulation , molecules = names ( colours ), mergeComplexes = FALSE , labels = id2names [ names ( colours )], colours = colours ) Simulated gene expression for the anthocyanin biosynthesis regulation pathway. The legend shows under which form (i.e. RNA, protein or regulatory copmplex) each component can be found. For example, MYB is present in both the 'RNAs' and the 'Proteins' plots, while MBW1 is a regulatory complex, and thus only appears in the 'Complexes' plot. Pretty neat! We can see that when the MYBrep gene is overexpressed, the activity of the pathway is reduced, and so the downstream enzymes responsible for the synthesis of anthocyanin (represented here by the DFR gene) are produced in smaller quantities. This leads to a reduction in the colouration of the plant. Why is scaling-up important \u00b6 The simulation above is nice, and allows us to get an idea of the dynamics of gene expression in both wild-type and mutated conditions. However, one stochastic simulation is not enough to draw robust conclusions. Ideally, the simulations should be repeated a large number of time in order to obtain distributions, rather than single values, for the abundance of different gene products. With a large number of simulations, we can then perform hypothesis testing, and draw solid conclusions. As an example, here is some of the output we can obtain after running 500 simulations: However, you will have noticed that each simulation takes a long time to run! sismonr records the simulation running time (in seconds) for each individual: sim $ runningtime [1] 201.192 190.206 which corresponds to approx. 3 minutes per simulation. So if we were to run, say, 2,000 simulations for each plant, it would take approximately 100 hours * ! This is why resources such as NeSI are essential for simulation-based research. In the next sections of this workshop, we will show you how to to (properly) scale-up these simulations on a High Performance Computer. * : actually, this estimate depends on how you run these 500 simulations. The running time of 3 minutes per simulation includes the time to transform the sismonr GRN object into a list of biochemical reactions, and to compute for each in silico individual the different reaction rates. If you were to run 2 simulations for each plant, with: sim <- simulateInSilicoSystem ( colsystem , plants , simtime = 1200 , ntrials = 2 ) you should notice that it doesn't take much more time than to run only one simulation per plant. This will not hold however if you start running a large number of simulations (e.g. setting ntrials = 10 will take more time to run). Back to homepage","title":"2. Getting started with sismonr"},{"location":"02_getting_started_sismonr/#2-getting-started-with-sismonr","text":"","title":"2. Getting started with sismonr"},{"location":"02_getting_started_sismonr/#introduction-to-the-sismonr-package","text":"The sismonr package was developed for the purpose of generating benchmark datasets, in order to assess the performance of statistical methods that reconstruct GRNs from experimental datasets such as RNAseq data. Therefore, sismonr allows the user to generate random GRNs that mimic some of the properties of biological regulatory networks. Alternatively, the user can construct their own regulatory network. sismonr can supports different types of regulation (e.g. transcription, translation or decay regulation). Genes can code for proteins or for non-coding regulatory RNAs; gene products can form regulatory complexes. One unique features of sismonr is that it allows the user to define the ploidy of the system, i.e. how many copies of each gene are present in the system. Lastly, sismonr simulates the expression of the genes in a GRN for different in silico individuals, that carry different versions (or alleles) of the genes present in the GRN (think of it as simulating gene expression from different subjects). This is quite useful to simulate gene expression under different scenarios such as gene knock-outs for example. If you are interested, a full tutorial is available here . One particularity of sismonr is that it is available as an R package; but internally it uses the programming language Julia to speed up some of the calculations. No worries though, you don't need to know anything about Julia to use sismonr!","title":"Introduction to the sismonr package"},{"location":"02_getting_started_sismonr/#how-sismonr-links-r-and-julia","text":"Before we get into the fun part, which is getting to play with the sismonr package, it is important to know a little bit about sismonr works. More specifically, we will now briefly cover how sismonr uses Julia to run the simulations and other computations. This will be important when scaling-up our work from a local machine to a HPC environment. sismonr handles communications between R and Julia via the XRJulia R package. The first time you use a function from the sismonr package that requires Julia, sismonr (via XRJulia functions) opens a new julia process on your computer, and sets up a socket connection between the R session and the new julia process. By default, this connection is set up on a random port, but there are ways to decide on the port to use: by executing, at the start of your R session, the following command: XRJulia :: newJuliaEvaluator ( port = as.integer ( 456 )) you are creating a new Julia process and the socket connection between the R session and the Julia process will use port 456. We won't need to use this for now, but you will find it useful later on :) Once the Julia process is started, whenever sismonr needs to run some computations in Julia, the necessary R objects are sent to the Julia process, which executes the required commands. Once done, the Julia process sends back the results to the R session. This way, the user doesn't have to interact with Julia at all. A very schematic representation of how sismonr uses the XRJulia package to run simulations in Julia from a R session. This is why, if you decide to use sismonr on your own computer, you will have to install Julia first, and make sure that R can find the Julia executable (for example by adding Julia to the PATH, which is done for you when installing Julia).","title":"How sismonr links R and Julia"},{"location":"02_getting_started_sismonr/#practice-time","text":"For this next section, you will need to login to NeSI Mahuika Jupyter and to open a sismonr Jupyter notebook. See here for instructions on how to login to NeSI Mahuika Jupyter and how to open a sismonr Jupyter kernel. Follow instructions up to S.2 2 (Guide Jupyter file explorer (left panel) to above working directory) included. Before opening a Jupyter Notebook, we will create a folder to save our work from this section: Now we can open a sismonr Jupyter Notebook: Before getting started, here are some abbreviations that are often used within sismonr: Abbreviations Meaning TC Transcription TL Translation RD RNA decay PD Protein decay PTM Post-translational modification PC Protein-coding NC Noncoding R RNA P Protein Pm Modified protein C Regulatory complex","title":"Practice time!"},{"location":"02_getting_started_sismonr/#generating-a-random-grn","text":"We will start by generating a small random GRN with sismonr, using the function createInSilicoSystem() . library ( sismonr ) set.seed ( 12 ) # important for reproducibility of \"random\" results in R! small_grn <- createInSilicoSystem ( G = 10 , # number of genes in the GRN PC.p = 1 , # proportion of genes that are protein-coding ploidy = 2 ) # ploidy of the system Note that the first time you run a sismonr command, you might have to wait a few seconds, as sismonr needs to open a new Julia process on your computer to execute some of the internal commands (such as the generation of a random GRN). You can visualise the GRN you just created with the following command (the resulting graph is interactive, try to hover over nodes or edges with your mouse, move nodes or click on nodes): plotGRN ( small_grn ) visNetwork {\"x\":{\"nodes\":{\"id\":[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"CTC1\"],\"type\":[\"Gene\",\"Gene\",\"Gene\",\"Gene\",\"Gene\",\"Gene\",\"Gene\",\"Gene\",\"Gene\",\"Gene\",\"Complex\"],\"coding\":[\"PC\",\"PC\",\"PC\",\"PC\",\"PC\",\"PC\",\"PC\",\"PC\",\"PC\",\"PC\",\"Complex\"],\"targetReaction\":[\"TC\",\"PD\",\"TC\",\"TC\",\"TC\",\"TL\",\"TL\",\"TL\",\"TL\",\"TC\",\"TC\"],\"label\":[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"CTC1\"],\"shape\":[\"ellipse\",\"ellipse\",\"ellipse\",\"ellipse\",\"ellipse\",\"ellipse\",\"ellipse\",\"ellipse\",\"ellipse\",\"ellipse\",\"box\"],\"color\":[\"#FF834A\",\"#7DCCFF\",\"#FF834A\",\"#FF834A\",\"#FF834A\",\"#579BDB\",\"#579BDB\",\"#579BDB\",\"#579BDB\",\"#FF834A\",\"#FF834A\"],\"borderWidth\":[0,0,0,0,0,0,0,0,0,0,2],\"group\":[\"1\",\"1\",\"1\",\"1\",\"1\",\"1\",\"1\",\"1\",\"1\",\"1\",\"1\"],\"title\":[\"1 (id: 1)<br>Protein-coding gene<br>Transcription regulator\",\"2 (id: 2)<br>Protein-coding gene<br>Regulator of protein decay\",\"3 (id: 3)<br>Protein-coding gene<br>Transcription regulator\",\"4 (id: 4)<br>Protein-coding gene<br>Transcription regulator\",\"5 (id: 5)<br>Protein-coding gene<br>Transcription regulator\",\"6 (id: 6)<br>Protein-coding gene<br>Translation regulator\",\"7 (id: 7)<br>Protein-coding gene<br>Translation regulator\",\"8 (id: 8)<br>Protein-coding gene<br>Translation regulator\",\"9 (id: 9)<br>Protein-coding gene<br>Translation regulator\",\"10 (id: 10)<br>Protein-coding gene<br>Transcription regulator\",\"CTC1 (id: CTC1)<br>Regulatory complex<br>Transcription regulator<br>Composed of: 10, 1\"]},\"edges\":{\"from\":[\"4\",\"5\",\"3\",\"1\",\"3\",\"5\",\"CTC1\",\"7\",\"9\",\"6\",\"8\",\"2\",\"10\",\"1\"],\"to\":[\"10\",\"10\",\"2\",\"3\",\"3\",\"5\",\"9\",\"2\",\"4\",\"7\",\"7\",\"1\",\"CTC1\",\"CTC1\"],\"type\":[\"Regulation\",\"Regulation\",\"Regulation\",\"Regulation\",\"Regulation\",\"Regulation\",\"Regulation\",\"Regulation\",\"Regulation\",\"Regulation\",\"Regulation\",\"Regulation\",\"Binding\",\"Binding\"],\"targetReaction\":[\"TC\",\"TC\",\"TC\",\"TC\",\"TC\",\"TC\",\"TC\",\"TL\",\"TL\",\"TL\",\"TL\",\"PD\",\"none\",\"none\"],\"sign\":[\"1\",\"-1\",\"-1\",\"1\",\"1\",\"1\",\"-1\",\"1\",\"-1\",\"-1\",\"-1\",\"1\",\"none\",\"none\"],\"arrows\":[\"to\",\"to\",\"to\",\"to\",\"to\",\"to\",\"to\",\"to\",\"to\",\"to\",\"to\",\"to\",null,null],\"color\":[null,null,null,null,null,null,null,null,null,null,null,null,\"#999999\",\"#999999\"],\"dashes\":[false,true,true,false,false,false,true,false,true,true,true,false,null,null],\"edge_meaning\":[\" activates the transcription of \",\" represses the transcription of \",\" represses the transcription of \",\" activates the transcription of \",\" activates the transcription of \",\" activates the transcription of \",\" represses the transcription of \",\" activates the translation of \",\" represses the translation of \",\" represses the translation of \",\" represses the translation of \",\" activates the protein decay of \",\" is part of complex \",\" is part of complex \"],\"title\":[\"4 activates the transcription of 10\",\"5 represses the transcription of 10\",\"3 represses the transcription of 2\",\"1 activates the transcription of 3\",\"3 activates the transcription of 3\",\"5 activates the transcription of 5\",\"CTC1 represses the transcription of 9\",\"7 activates the translation of 2\",\"9 represses the translation of 4\",\"6 represses the translation of 7\",\"8 represses the translation of 7\",\"2 activates the protein decay of 1\",\"10 is part of complex CTC1\",\"1 is part of complex CTC1\"]},\"nodesToDataframe\":true,\"edgesToDataframe\":true,\"options\":{\"width\":\"100%\",\"height\":\"100%\",\"nodes\":{\"shape\":\"dot\",\"size\":20,\"physics\":false},\"manipulation\":{\"enabled\":false},\"layout\":{\"randomSeed\":123,\"improvedLayout\":true},\"physics\":{\"timestep\":1}},\"groups\":[\"1\"],\"width\":\"800px\",\"height\":null,\"idselection\":{\"enabled\":false,\"style\":\"width: 150px; height: 26px\",\"useLabels\":true,\"main\":\"Select by id\"},\"byselection\":{\"enabled\":false,\"style\":\"width: 150px; height: 26px\",\"multiple\":false,\"hideColor\":\"rgba(200,200,200,0.5)\",\"highlight\":false},\"main\":null,\"submain\":null,\"footer\":null,\"background\":\"rgba(0, 0, 0, 0)\",\"highlight\":{\"enabled\":true,\"hoverNearest\":false,\"degree\":1,\"algorithm\":\"all\",\"hideColor\":\"rgba(200,200,200,0.5)\",\"labelOnly\":true},\"collapse\":{\"enabled\":false,\"fit\":false,\"resetHighlight\":true,\"clusterOptions\":null,\"keepCoord\":true,\"labelSuffix\":\"(cluster)\"},\"legend\":{\"width\":0.2,\"useGroups\":false,\"position\":\"left\",\"ncol\":1,\"stepX\":100,\"stepY\":80,\"zoom\":true,\"edges\":{\"label\":[\"\\n\\nActivation\",\"\\n\\nRepression\",\"\\n\\n Part of complex\"],\"color\":[\"black\",\"black\",\"#999999\"],\"arrows\":[\"to\",\"to\",null],\"dashes\":[null,true,null]},\"edgesToDataframe\":true,\"nodes\":{\"label\":[\"Protein-coding gene\",\"Non-coding gene\",\"Regulatory complex\",\"Transcription regulator\",\"Translation regulator\",\"Regulator of RNA decay\",\"Regulator of protein decay\",\"Regulator of post-\\ntranslational modification\"],\"shape\":[\"ellipse\",\"diamond\",\"box\",\"diamond\",\"diamond\",\"diamond\",\"diamond\",\"diamond\"],\"color\":[\"#F2F2F2\",\"#F2F2F2\",\"#F2F2F2\",\"#FF834A\",\"#579BDB\",\"#FFB746\",\"#7DCCFF\",\"#4BC095\"],\"borderWidth\":[0,0,2,0,0,0,0,0]},\"nodesToDataframe\":true,\"main\":{\"text\":\"Legend\",\"style\":\"font-family:Georgia, Times New Roman, Times, serif;font-weight:bold;font-size:14px;text-align:center;\"}}},\"evals\":[],\"jsHooks\":[]} {\"viewer\":{\"width\":\"800px\",\"height\":350,\"padding\":0,\"fill\":false},\"browser\":{\"width\":\"800px\",\"height\":500,\"padding\":0,\"fill\":false}} Alternatively, you can get a list of the genes and regulatory relationships in the GRN through: getGenes ( small_grn ) id coding TargetReaction PTMform ActiveForm TCrate TLrate RDrate PDrate 1 1 PC TC 0 P1 0.0010706485 0.115208445 0.0006563273 0.0003594616 2 2 PC PD 0 P2 0.0007063012 1.096787613 0.0002886745 0.0008614784 3 3 PC TC 0 P3 0.0010690560 0.016254643 0.0004565128 0.0002589524 4 4 PC TC 0 P4 0.0020231676 0.006923935 0.0008362586 0.0011683879 5 5 PC TC 0 P5 0.0017721606 0.021329358 0.0011665348 0.0004787676 6 6 PC TL 0 P6 0.0011366749 0.017786830 0.0008228596 0.0002831087 7 7 PC TL 0 P7 0.0052234381 0.060540559 0.0007973883 0.0007609887 8 8 PC TL 0 P8 0.0026365016 0.017948936 0.0006848954 0.0003388916 9 9 PC TL 0 P9 0.0030150020 0.140724990 0.0006802817 0.0002328448 10 10 PC TC 0 P10 0.0015819471 0.007701612 0.0006157945 0.0005439300 and: getEdges ( small_grn ) from to TargetReaction RegSign RegBy 1 4 10 TC 1 PC 2 5 10 TC -1 PC 3 3 2 TC -1 PC 4 1 3 TC 1 PC 5 3 3 TC 1 PC 6 5 5 TC 1 PC 7 CTC1 9 TC -1 C 8 7 2 TL 1 PC 9 9 4 TL -1 PC 10 6 7 TL -1 PC 11 8 7 TL -1 PC 12 2 1 PD 1 PC Note that you can modify the properties of your system by changing the values in these data-frames. The createInSilicoSystem function accepts many arguments allowing the user to customise the GRN to be created. You can find a list of these by tying: ? insilicosystemargs For example, you can generate a network of 5 genes with only protein-coding genes that are regulators of transcription with: set.seed ( 45 ) another_grn <- createInSilicoSystem ( G = 5 , PC.p = 1 , PC.TC.p = 1 ) # all protein-coding genes are # regulators of transcription","title":"Generating a random GRN"},{"location":"02_getting_started_sismonr/#modifying-a-grn","text":"In addition, you can add genes in your GRN, and add or remove regulatory relationships between genes (currently it is not possible to remove genes, this option will be added in the future). When adding a gene, you can specify its kinetic parameters, e.g. its transcription rate (in RNA/sec), RNA decay rate, etc. small_grn2 <- addGene ( small_grn , coding = \"PC\" , TCrate = 0.01 , RDrate = 0.005 ) Same thing when adding an edge to the GRN: you can decide if the regulation is activative or repressive, and the different rates of the regulation: small_grn3 <- addEdge ( small_grn2 , regID = 11 , tarID = 8 , regsign = \"1\" )","title":"Modifying a GRN"},{"location":"02_getting_started_sismonr/#simulating-genetically-diverse-in-silico-individuals","text":"Two individuals from a same species are not genetically identical. They carry the different versions (called alleles) of the same genes. Genetic mutations in or around a gene influence the dynamics of gene expression. To account for that, sismonr does not directly simulate the expression of genes in a GRN, but simulates the expression of the genes for different in silico individuals. More details can be found in the sismonr tutorial . Once you've created a GRN with sismonr, you can generate in silico individuals with the createInSilicoPopulation function. For example, let us generate 3 random in silico individuals; we'll assume that for each gene, they can carry one of 2 possible alleles (this can be customised further but we won't go into details). set.seed ( 123 ) small_pop <- createInSilicoPopulation ( 3 , # number of individuals small_grn , # our GRN ngenevariants = 2 ) # how many alleles exist per gene We can visualise the difference between the individuals via: plotMutations ( small_pop , small_grn , nGenesPerRow = 5 ) A plot representing, for each in silico individual (rows) and each gene (columns), the effect (colour) of genetic mutations on different aspects of the gene's expression (x-axis) for each allele (y-axis) carried by the individual. For noncoding genes, some QTL effect coefficients are not relevant (the ones related to protein or translation) and are represented in gray. For example, in silico individual Ind1 has no mutation on any of its copies of gene 1. It carries two different alleles of gene 2. Tip : to increase the size of the figure generated in a Jupyter notebook cell, add the following command at the top of the cell: options ( repr.plot.width = 18 , repr.plot.height = 12 )","title":"Simulating genetically diverse in silico individuals"},{"location":"02_getting_started_sismonr/#generating-a-stochastic-model-with-the-sismonr-package","text":"As mentioned previously, simulators rely on a set of rules to convert the GRN into a mathematical or statistical model that can be used to simulate gene expression over time. This set of rules will depend on the type of model we want to construct (boolean, deterministic, etc). In the case of a stochastic model, we must decide how to transform a graph representing regulatory interactions between genes into a set of biochemical reactions. There is no correct answer. The modelling decisions will influence the precision of the model, with biological accuracy balancing computational efficiency. As an example, the sismonr uses the following rules: This is how sismonr models different type of expression regulation. Each arrow \\(i \\rightarrow j\\) in the GRN is transformed into a set of biochemical reactions with associated rates, as presented. For example, the following small GRN: A small GRN with 3 genes; gene 1 activates the transcription of gene 2; gene 2 activates the transcription of gene 3; and gene 3 represses the transcription of gene 1. is transformed into the following set of reactions: ## Binding/unbinding of regulators to/from their target's DNA Pr2reg1F + P1 --> Pr2reg1B Pr2reg1B --> Pr2reg1F + P1 Pr3reg2F + P2 --> Pr3reg2B Pr3reg2B --> Pr3reg2F + P2 Pr1reg3F + P3 --> Pr1reg3B Pr1reg3B --> Pr1reg3F + P3 ## Basal and regulated transcription Pr1reg3F --> Pr1reg3F + R1 Pr2reg1F --> Pr2reg1F + R2 Pr2reg1B --> Pr2reg1B + R2 Pr3reg2F --> Pr3reg2F + R3 Pr3reg2B --> Pr3reg2B + R3 ## Translation R1 --> R1 + P1 R2 --> R2 + P2 R3 --> R3 + P3 ## RNA decay R1 --> 0 R2 --> 0 R3 --> 0 ## Protein decay (including those bound to DNA) P1 --> 0 Pr2reg1B --> Pr2reg1F P2 --> 0 Pr3reg2B --> Pr3reg2F P3 --> 0 Pr1reg3B --> Pr1reg3F where : PrXregY represents the DNA region of gene X where regulator Y binds; PrXregYF represents the region with no bound regulator (free), and PrXregYB represents the region with a regulator bound to it RX represents the RNA produced by gene X; PX represents the protein produced by gene X. (It's actually a bit more complicated than that, as sismonr accounts for the ploidy of the system, i.e. how many copies of each gene are present, and tracks each copy separately). If you are interested, the code to reproduce this example is available here . One crucial thing to understand is that a reaction in a stochastic system is a simplified representation of a set of true biochemical reactions happening in the biological system. For example, in the example above, the reaction R1 --> R1 + P1 , which represents the translation of gene 1, ignores the fact that the translation of a messenger RNA is a very complex process involving many steps and molecular actors. Decisions must also be made about the rate of the different reactions, as well as the initial abundance of the molecules when the simulation starts. This is again a very complex step in the creation of a model, as it is quite arduous to precisely estimate the rate of different biochemical reactions in vivo . When constructing a stochastic model for a given GRN, sismonr computes for each reaction in the model a constant rate (i.e. the probability of one molecule of each reactant to collide and undergo the reaction in one unit of time), which depends on the properties of the genes (e.g. transcription rate) and of the GRN (e.g. strength of regulation). These rates will be influenced by \"genetic mutations\" that differentiate the in silico individuals modelled by sismonr. Here are the rates of each reaction for two genetically different in silico individuals: reaction rate_Ind1 rate_Ind2 Pr2reg1F + P1 --> Pr2reg1B 5.89e-06 5.27e-06 Pr2reg1B --> Pr2reg1F + P1 2.45e-03 2.45e-03 Pr3reg2F + P2 --> Pr3reg2B 3.46e-05 3.32e-05 Pr3reg2B --> Pr3reg2F + P2 2.86e-03 2.86e-03 Pr1reg3F + P3 --> Pr1reg3B 1.36e-06 1.25e-06 Pr1reg3B --> Pr1reg3F + P3 9.84e-04 9.84e-04 Pr1reg3F --> Pr1reg3F + R1 6.54e-04 6.54e-04 Pr2reg1F --> Pr2reg1F + R2 1.13e-03 1.22e-03 Pr2reg1B --> Pr2reg1B + R2 7.75e-03 8.39e-03 Pr3reg2F --> Pr3reg2F + R3 1.63e-03 1.54e-03 Pr3reg2B --> Pr3reg2B + R3 8.28e-03 7.84e-03 R1 --> R1 + P1 1.02e-01 1.02e-01 R2 --> R2 + P2 8.88e-03 8.69e-03 R3 --> R3 + P3 3.09e-01 3.22e-01 R1 --> 0 6.20e-04 6.20e-04 R2 --> 0 6.48e-04 5.78e-04 R3 --> 0 4.55e-04 4.57e-04 P1 --> 0 1.95e-04 1.95e-04 Pr2reg1B --> Pr2reg1F 1.95e-04 1.95e-04 P2 --> 0 1.23e-04 1.13e-04 Pr3reg2B --> Pr3reg2F 1.23e-04 1.13e-04 P3 --> 0 1.02e-03 1.05e-03 Pr1reg3B --> Pr1reg3F 1.02e-03 1.05e-03 The list of reactions and associated rates is what sismonr uses to simulate the expression of the genes over time for each in silico individual. Tip : The getReactions() function from sismonr allows you to see the list of biochemical reactions and associated rates for a GRN. There are two ways to use the function. Providing only the GRN object as an input to the function, as follows: getReactions ( small_grn ) will return a data-frame with the list of biochemical reactions, their name and the formula used by sismonr to compute their constant rate. If you also provide the in silico inviduals as an input to the function, like so: getReactions ( small_grn , small_pop ) the resulting data-frame will contain, in addition to the columns previously described, one column for each in silico individual giving the constant rate of the reactions for this individual.","title":"Generating a stochastic model with the sismonr package"},{"location":"02_getting_started_sismonr/#workshops-challenge-modelling-the-anthocyanin-biosynthesis-regulation-pathway-in-eudicots","text":"For this workshop, we will work on a model for the anthocyanin biosynthesis regulation pathway in eudicots . Anthocyanins are pgiments providing colouration to plants, flowers and fruits. This model was developed (mainly) based on the following sources: Albert, Nick W., et al. \"A conserved network of transcriptional activators and repressors regulates anthocyanin pigmentation in eudicots.\" The Plant Cell 26.3 (2014): 962-980. https://doi.org/10.1105/tpc.113.122069 Liu, Ying, et al. \"Anthocyanin biosynthesis and degradation mechanisms in Solanaceous vegetables: a review.\" Frontiers in Chemistry 6 (2018): 52. https://doi.org/10.3389/fchem.2018.00052 Xu, Wenjia, Christian Dubos, and Lo\u00efc Lepiniec. \"Transcriptional control of flavonoid biosynthesis by MYB\u2013bHLH\u2013WDR complexes.\" Trends in plant science 20.3 (2015): 176-185. https://doi.org/10.1016/j.tplants.2014.12.001 Baudry, Antoine, et al. \"TT2, TT8, and TTG1 synergistically specify the expression of BANYULS and proanthocyanidin biosynthesis in Arabidopsis thaliana.\" The Plant Journal 39.3 (2004): 366-380. https://doi.org/10.1111/j.1365-313X.2004.02138.x An animation of the GRN is presented below: \ud83e\udd13 Schema of the model of the anthocyanin biosynthesis regulation pathway. A static image of the model can be found here . The GRN starts with 3 protein-genes, MYB , bHLH1 and WDR . While bHLH1 and WDR are constitutively expressed (i.e. constantly produce proteins), MYB is only expressed in response to certain inductive conditions such as the presence of light. Their proteins assemble into a regulatory complex (termed MBW1), which activates the transcription of the bHLH2 gene. The synthesised bHLH2 proteins form a second regulatory complex with the MYB and WDR proteins (termed MBW2). This complex then activates the transcription of downstream genes encoding for enzymes involved in the anthocyanin biosynthesis pathway. The presence of these enzymes result in the production of anthocyanin. Here we use the DFR gene as a representative example of MBW2's targets. We will assume that the abundance of DFR proteins acts as a proxy for the production of anthocyanins. In addition, the MBW2 complex also activates the transcription of two repressors genes, MYBrep and R3-MYB , which form a negative feedback loop in the GRN. Both genes repress the activity of the network through different means. The MYBrep proteins bind the MBW2 complex (this new complex is termed MBWr), which becomes a repressor complex. It will inhibit the transcription of bHLH2 , which in turn reduces the expression of the downstream enzymes and thus modulates the production of anthocyanin. It also directly inhibits the expression of the MBW2 targets, including MYBrep and DFR . The R3-MYB exert instead a passive repression on the system, by binding to bHLH1 and bHLH2 proteins, thus reducing the number of available bHLH1 and bHLH2 proteins in the system. In consequence, this reduces the number of MBW1 and MBW2 complexes in the system and in turn reduces the activity of the network. The goal of this workshop will be to simulate the expression of the different genes in the pathway over a period of 1,200 seconds (20 minutes) after induction of the MYB gene. We will simulate the GRN for two different in silico plants: A wild type plant: the different kinetic parameters are set to the default values; A mutant plant in which the MYBrep gene is overexpressed: the transcription rate of the gene is increased 50-fold. This can be achieved experimentally by transforming a plant, in order to modify the promoter of the target gene. Because the simulations are stochastic, it is better to simulate the GRN a large number of times in order to obtain a good overview of the system behaviour. We will aim to produce 2,000 simulations. In order to save time, the GRN and the in silico plants have already been generated with sismonr. The R script used to generate it can be found here . The sismonr objects representing the anthocyanin biosynthesis regulation network and the in silico plants are saved in the following .RData file: /nesi/project/nesi02659/sismonr_workshop/sismonr_anthocyanin_system.RData Alternatively, it can be downloaded here . You will start by creating a copy of this object in your working directory, for easier access. In a terminal, type: $ cp /nesi/project/nesi02659/sismonr_workshop/sismonr_anthocyanin_system.RData ~/sism_2021/ You can check that it worked with: $ ls -l ~/sism_2021/ total 0 -r--r-----+ 1 oangelin nesi02659 5417 Nov 22 17 :05 sismonr_anthocyanin_system.RData","title":"Workshop's challenge: modelling the anthocyanin biosynthesis regulation pathway in eudicots"},{"location":"02_getting_started_sismonr/#running-a-first-simulation-interactive","text":"You will start by running one simulation on your local machine. This is the first thing to do if you are planning to run simulations on NeSI: first, make sure your code actually works! For this workshop, a jupyter kernel will act as your local machine. Start by opening a sismonr kernel (see the instructions here ). We will first load the sismonr package, and the model and in silico plants we want to simulate. Create a new sismonr Jupyter Notebook and add: library ( sismonr ) load ( \"~/sism_2021/sismonr_anthocyanin_system.RData\" ) This sismonr_anthocyanin_system.RData file contains the following R objects: colsystem : the in silico GRN constructed with sismonr; plants : the in silico population of individuals corresponding to the GRN; id2names : character vector that links the ID of the genes and regulatory complexes in the colsystem GRN to their name; colours : character vector that assigns each gene and regulatory complex its own colour (for plotting purposes). Feel free to inspect the different aspects of the model (using for example plotGRN(colsystem) , plotMutations(plants, colsystem) or getReactions(colsystem, plants) ). We can run one simulation for each of the two in silico plants via the command: set.seed ( 123 ) sim <- simulateInSilicoSystem ( colsystem , plants , simtime = 1200 , ntrials = 1 ) Where simtime is the time (in seconds) for which we want to simulate the expression of the genes; ntrials corresponds to the number of times we want to repeat the simulation for each in silico individual. This should take around six minutes to complete. Once this is done, you can visualise the result with the plotSimulation function. There is the option to display only a certain subset of molecules (we'll ignore all intermediary complexes so as to not clutter the graph), and to provide custom colours and labels for the different components: plotSimulation ( sim $ Simulation , molecules = names ( colours ), mergeComplexes = FALSE , labels = id2names [ names ( colours )], colours = colours ) Simulated gene expression for the anthocyanin biosynthesis regulation pathway. The legend shows under which form (i.e. RNA, protein or regulatory copmplex) each component can be found. For example, MYB is present in both the 'RNAs' and the 'Proteins' plots, while MBW1 is a regulatory complex, and thus only appears in the 'Complexes' plot. Pretty neat! We can see that when the MYBrep gene is overexpressed, the activity of the pathway is reduced, and so the downstream enzymes responsible for the synthesis of anthocyanin (represented here by the DFR gene) are produced in smaller quantities. This leads to a reduction in the colouration of the plant.","title":"Running a first simulation (interactive)"},{"location":"02_getting_started_sismonr/#why-is-scaling-up-important","text":"The simulation above is nice, and allows us to get an idea of the dynamics of gene expression in both wild-type and mutated conditions. However, one stochastic simulation is not enough to draw robust conclusions. Ideally, the simulations should be repeated a large number of time in order to obtain distributions, rather than single values, for the abundance of different gene products. With a large number of simulations, we can then perform hypothesis testing, and draw solid conclusions. As an example, here is some of the output we can obtain after running 500 simulations: However, you will have noticed that each simulation takes a long time to run! sismonr records the simulation running time (in seconds) for each individual: sim $ runningtime [1] 201.192 190.206 which corresponds to approx. 3 minutes per simulation. So if we were to run, say, 2,000 simulations for each plant, it would take approximately 100 hours * ! This is why resources such as NeSI are essential for simulation-based research. In the next sections of this workshop, we will show you how to to (properly) scale-up these simulations on a High Performance Computer. * : actually, this estimate depends on how you run these 500 simulations. The running time of 3 minutes per simulation includes the time to transform the sismonr GRN object into a list of biochemical reactions, and to compute for each in silico individual the different reaction rates. If you were to run 2 simulations for each plant, with: sim <- simulateInSilicoSystem ( colsystem , plants , simtime = 1200 , ntrials = 2 ) you should notice that it doesn't take much more time than to run only one simulation per plant. This will not hold however if you start running a large number of simulations (e.g. setting ntrials = 10 will take more time to run). Back to homepage","title":"Why is scaling-up important"},{"location":"03_scaling_up/","text":"3. Scaling up your work \u00b6 Introduction to HPC \u00b6 Defining high-performance computing \u00b6 The simplest way of defining high-performance computing is by saying that it is the using of high-performance computers (HPC). However, this leads to our next question what is a HPC . HPC A high-performance computer is a network of computers in a cluster that typically share a common purpose and are used to accomplish tasks that might otherwise be too big for any one computer. While modern computers can do a lot (and a lot more than their equivalents 10-20 years ago), there are limits to what they can do and the speed at which they are able to do this. One way to overcome these limits is to pool computers together to create a cluster of computers. These pooled resources can then be used to run software that requires more total memory, or need more processors to complete in a reasonable time. One way to do this is to take a group of computers and link them together via a network switch. Consider a case where you have five 4-core computers. By connecting them together, you could run jobs on 20 cores, which could result in your software running faster. HPC architectures \u00b6 Most HPC systems follow the ideas described above of taking many computers and linking them via network switches. described above is: What distinguishes a high-performance computer from the computer clusters The number of computers/nodes The strength of each individual computer/node The network interconnect \u2013 this dictates the communication speed between nodes. The faster this speed is, the more a group of individual nodes will act like a unit. NeSI Mahuika Cluster architecture \u00b6 NeSI Mahuika cluster (CRAY HPE CS400) system consists of a number of different node types. The ones visible to researchers are: Login nodes Compute nodes Overview of HPC Architecture Composition of a node In reality From Hardware to Software \u00b6 Over 90% HPCs & supercomputers employ Linux as their operating system. Linux has four essential properties which make it an excellent operating system for the HPCs & science community: Performance Functionality Flexibility Portability Performance of the operating system can be optimized for specific tasks such as running small portable devices or large supercomputers. A number of community-driven scientific applications and libraries have been developed under Linux such as molecular dynamics, linear algebra, and fast-Fourier transforms. The system is flexible enough to allow users to build applications with a wide array of support tools such as compilers, scientific libraries, debuggers, and network monitors. The operating system, utilities, and libraries have been ported to a wide variety of devices including desktops, clusters, supercomputers, mainframes, embedded systems, and smart phones. The Linux operating system is made up of three parts; the kernel , the shell and the software Kernel \u2212 The kernel is the heart of the operating system. It interacts with the hardware and most of the tasks like memory management, task scheduling and file management. Shell \u2212 The shell is the utility that processes your requests (acts as an interface between the user and the kernel). When you type in a command at your terminal, the shell interprets (operating as in interpreter ) the command and calls the program that you want. The shell uses standard syntax for all commands. The shell recognizes a limited set of commands, and you must give commands to the shell in a way that it understands: Each shell command consists of a command name, followed by command options (if any are desired) and command arguments (if any are desired). The command name, options, and arguments, are separated by blank space. An interpreter operates in a simple loop: It accepts a command, interprets the command, executes the command, and then waits for another command. The shell displays a \"prompt,\" to notify you that it is ready to accept your command. Accessing software via modules \u00b6 On a high-performance computing system, it is quite rare that the software we want to use is available when we log in. It is installed, but we will need to \u201cload\u201d it before it can run. Before we start using individual software packages, however, we should understand the reasoning behind this approach. The three biggest factors are: software incompatibilities versioning dependencies One of the workarounds for this issue is Environment modules. A module is a self-contained description of a software package \u2014 it contains the settings required to run a software package and, usually, encodes required dependencies on other software packages. There are a number of different environment module implementations commonly used on HPC systems and the one used in NeSI Mahuika cluster is Lmod where the module command is used to interact with environment modules. Viewing, Accessing and Deploying software with module command\" View available modules #View all modules $ module avail # View all modules which match the keyword in their name $ module avail KEYWORD # View all modules which match the keyword in their name or description $ module spider KEYWORD Load a specific program All module names on NeSI Software stack have a version and toolchain/environment suffixes. If none is specified, then the default version of the software is loaded. The default version can be seen with the module avail modulename command (corresponding module name will have (D) suffix) $ module load MY_APPLICATION Unload all current modules $ module purge Please do not use $module --force purge Swap a currently loaded module for a different one $ module switch CURRENT_MODULE DESIRED_MODULE Back to homepage","title":"3. Scaling up your work"},{"location":"03_scaling_up/#3-scaling-up-your-work","text":"","title":"3. Scaling up your work"},{"location":"03_scaling_up/#introduction-to-hpc","text":"","title":"Introduction to HPC"},{"location":"03_scaling_up/#defining-high-performance-computing","text":"The simplest way of defining high-performance computing is by saying that it is the using of high-performance computers (HPC). However, this leads to our next question what is a HPC . HPC A high-performance computer is a network of computers in a cluster that typically share a common purpose and are used to accomplish tasks that might otherwise be too big for any one computer. While modern computers can do a lot (and a lot more than their equivalents 10-20 years ago), there are limits to what they can do and the speed at which they are able to do this. One way to overcome these limits is to pool computers together to create a cluster of computers. These pooled resources can then be used to run software that requires more total memory, or need more processors to complete in a reasonable time. One way to do this is to take a group of computers and link them together via a network switch. Consider a case where you have five 4-core computers. By connecting them together, you could run jobs on 20 cores, which could result in your software running faster.","title":"Defining high-performance computing"},{"location":"03_scaling_up/#hpc-architectures","text":"Most HPC systems follow the ideas described above of taking many computers and linking them via network switches. described above is: What distinguishes a high-performance computer from the computer clusters The number of computers/nodes The strength of each individual computer/node The network interconnect \u2013 this dictates the communication speed between nodes. The faster this speed is, the more a group of individual nodes will act like a unit.","title":"HPC architectures"},{"location":"03_scaling_up/#nesi-mahuika-cluster-architecture","text":"NeSI Mahuika cluster (CRAY HPE CS400) system consists of a number of different node types. The ones visible to researchers are: Login nodes Compute nodes Overview of HPC Architecture Composition of a node In reality","title":"NeSI Mahuika Cluster architecture"},{"location":"03_scaling_up/#from-hardware-to-software","text":"Over 90% HPCs & supercomputers employ Linux as their operating system. Linux has four essential properties which make it an excellent operating system for the HPCs & science community: Performance Functionality Flexibility Portability Performance of the operating system can be optimized for specific tasks such as running small portable devices or large supercomputers. A number of community-driven scientific applications and libraries have been developed under Linux such as molecular dynamics, linear algebra, and fast-Fourier transforms. The system is flexible enough to allow users to build applications with a wide array of support tools such as compilers, scientific libraries, debuggers, and network monitors. The operating system, utilities, and libraries have been ported to a wide variety of devices including desktops, clusters, supercomputers, mainframes, embedded systems, and smart phones. The Linux operating system is made up of three parts; the kernel , the shell and the software Kernel \u2212 The kernel is the heart of the operating system. It interacts with the hardware and most of the tasks like memory management, task scheduling and file management. Shell \u2212 The shell is the utility that processes your requests (acts as an interface between the user and the kernel). When you type in a command at your terminal, the shell interprets (operating as in interpreter ) the command and calls the program that you want. The shell uses standard syntax for all commands. The shell recognizes a limited set of commands, and you must give commands to the shell in a way that it understands: Each shell command consists of a command name, followed by command options (if any are desired) and command arguments (if any are desired). The command name, options, and arguments, are separated by blank space. An interpreter operates in a simple loop: It accepts a command, interprets the command, executes the command, and then waits for another command. The shell displays a \"prompt,\" to notify you that it is ready to accept your command.","title":"From Hardware to Software"},{"location":"03_scaling_up/#accessing-software-via-modules","text":"On a high-performance computing system, it is quite rare that the software we want to use is available when we log in. It is installed, but we will need to \u201cload\u201d it before it can run. Before we start using individual software packages, however, we should understand the reasoning behind this approach. The three biggest factors are: software incompatibilities versioning dependencies One of the workarounds for this issue is Environment modules. A module is a self-contained description of a software package \u2014 it contains the settings required to run a software package and, usually, encodes required dependencies on other software packages. There are a number of different environment module implementations commonly used on HPC systems and the one used in NeSI Mahuika cluster is Lmod where the module command is used to interact with environment modules. Viewing, Accessing and Deploying software with module command\" View available modules #View all modules $ module avail # View all modules which match the keyword in their name $ module avail KEYWORD # View all modules which match the keyword in their name or description $ module spider KEYWORD Load a specific program All module names on NeSI Software stack have a version and toolchain/environment suffixes. If none is specified, then the default version of the software is loaded. The default version can be seen with the module avail modulename command (corresponding module name will have (D) suffix) $ module load MY_APPLICATION Unload all current modules $ module purge Please do not use $module --force purge Swap a currently loaded module for a different one $ module switch CURRENT_MODULE DESIRED_MODULE Back to homepage","title":"Accessing software via modules"},{"location":"04_working_with_job_scheduler/","text":"4. Working with job scheduler \u00b6 Introduction to slurm scheduler and directives \u00b6 An HPC system might have thousands of nodes and thousands of users. How do we decide who gets what and when? How do we ensure that a task is run with the resources it needs? This job is handled by a special piece of software called the scheduler. On an HPC system, the scheduler manages which jobs run where and when. In brief, scheduler is a Mechanism to control access by many users to shared computing resources Queuing / scheduling system for users\u2019 jobs Manages the reservation of resources and job execution on these resources Allows users to \u201cfire and forget\u201d large, long calculations or many jobs (\u201cproduction runs\u201d) Why do we need a scheduler ? To ensure the machine is utilised as fully as possible To ensure all users get a fair chance to use compute resources (demand usually exceeds supply) To track usage - for accounting and budget control To mediate access to other resources e.g. software licences Commonly used schedulers Slurm PBS , Torque Grid Engine LSF \u2013 IBM Systems Researchers can not communicate directly to Compute nodes from the login node. Only way to establish a connection OR send scripts to compute nodes is to use scheduler as the carrier/manager All NeSI clusters use Slurm (Simple Linux Utility for Resource Management) scheduler (or job submission system) to manage resources and how they are made available to users. Life cycle of a slurm job \u00b6 The main commands you will use with Slurm on NeSI Mahuika cluster are: Command Function sbatch Submit non-interactive (batch) jobs to the scheduler squeue List jobs in the queue scancel Cancel a job sacct Display accounting data for all jobs and job steps in the Slurm job accounting log or Slurm database srun Slurm directive for parallel computing sinfo Query the current state of nodes salloc Submit interactive jobs to the scheduler A quick note on sinfo (Query the current state of nodes) which is not a command a researcher will use regularly but helps HPC admins and support staff with monitoring. Exercise 4.1 Let's run the following commands and discuss the outputs #summary of current states of compute nodes known to the scheduler $ sinfo #similar to above but expanded $ sinfo --format = \"%16P %.8m %.5a %10T %.5D %80N\" #will print a long output as it is one row per compute node in the cluster $ sinfo -N -l #Explore the capacity of a compute node $ sinfo -n wch001 -o \"%n %c %m\" Anatomy of a slurm script and submitting first slurm job \ud83e\uddd0 \u00b6 As with most other scheduler systems, job submission scripts in Slurm consist of a header section with the shell specification and options to the submission command ( sbatch in this case) followed by the body of the script that actually runs the commands you want. In the header section, options to sbatch should be prepended with #SBATCH . Commented lines are ignored by the bash interpreter, but they are not ignored by slurm. The #SBATCH parameters are read by slurm when we submit the job. When the job starts, the bash interpreter will ignore all lines starting with # . This is very similar to the shebang mentioned earlier, when you run your script, the system looks at the #! , then uses the program at the subsequent path to interpret the script, in our case /bin/bash (the program bash found in the /bin directory header use description --job-name #SBATCH --job-name=MyJob The name that will appear when using squeue or sacct. --account #SBATCH --account=nesi12345 The account your core hours will be 'charged' to. --time #SBATCH --time=DD-HH:MM:SS Job max walltime. --mem #SBATCH --mem=512MB Memory required per node. --cpus-per-task #SBATCH --cpus-per-task=10 Will request 10 logical CPUs per task. --output #SBATCH --output=%j_output.out Path and name of standard output file. %j will be replaced by the job ID. --mail-user #SBATCH --mail-user=me23@gmail.com address to send mail notifications. --mail-type #SBATCH --mail-type=ALL Will send a mail notification at BEGIN END FAIL. #SBATCH --mail-type=TIME_LIMIT_80 Will send message at 80% walltime. Exercise 4.2 First create a new working directory and write the script #Change working directory to your personal wd $ cd /nesi/project/nesi02659/sismonr_workshop/workingdir/ $USER #confirm the path is correct (me123 is just a place holder for the place where you should see your username) $ pwd /nesi/project/nesi02659/sismonr_workshop/workingdir/me123/ #create a new directory for this section and change the directory to it $ mkdir Exercise_4.2 && cd Exercise_4.2 #use a text editor of choice to create a file named firstslurm.sl - we will use nano here $ nano firstslurm.sl Content of firstslurm.sl should be as below. Please discuss as you make progress #!/bin/bash #SBATCH --job-name myfirstslurmjob #SBATCH --account nesi02659 #SBATCH --time 00:01:00 #SBATCH --cpus-per-task 1 #SBATCH --mem 512 #SBATCH --output slurmjob.%j.out sleep 40 echo \"I am a slurm job and I slept for 40 seconds\" echo \" $SLURM_JOB_ID END\" Save and Exit Submit the script with sbatch command $ sbatch firstslurm.sl Execute squeue --me and sacct . Discuss the outputs .i.e. $ squeue --me $ sacct STDOUT/STDERR from jobs \u00b6 STDOUT - your process writes conventional output to this file handle STDERR - your process writes diagnostic output to this file handle. STDOUT and STDERR from jobs are, by default, written to a file called slurm-JOBID.out and slurm-JOBID.err in the working directory for the job (unless the job script changes this, this will be the directory where you submitted the job). So for a job with ID 12345 STDOUT and STDERR would be in slurm-12345.out and slurm-12345.err . When things go wrong, first step of debugging (STORY TIME !) starts with a referral to these files. Assessing resource utilisation (cpu, memory, time) \u00b6 Understanding the resources you have available and how to use them most efficiently is a vital skill in high performance computing. The three resources that every single job submitted on the platform needs to request are: CPUs (i.e. logical CPU cores), and Memory (RAM), and Time. What happens if I ask for the wrong resources? Resource Asking for too much Not asking for enough Number of CPUs Job may wait in the queue for longer Job will run more slowly than expected, and so may run out time Drop in fairshare score which determines job priority Memory (above) Job will fail, probably with OUT OF MEMORY error, segmentation fault or bus error Wall time (above) Job will run out of time and get killed Exercise 4.3 Let's submit another slurm job and review its resource utilisation #Change the working directory to Exercise_4.3 $ cd /nesi/project/nesi02659/sismonr_workshop/workingdir/ $USER /Exercise_4.3 #Run ls command and you should see two files (one .R and one sl) and one directory named slurmout $ ls -F example1_arraysum.R example1_arraysum.sl slurmout/ #Review the slurm script with cat Or another text editor and submit with sbatch $ sbatch example1_arraysum.sl use squeue --me and sacct again to evaluate the job status Once the job ran into completion, use nn_seff JOBID command to print the resource utilisation statistics (Replace JOBID with the corresponding number) $ nn_seff 23263188 Job ID: 23263188 Cluster: mahuika User/Group: me1234/me123 State: COMPLETED ( exit code 0 ) Cores: 1 Tasks: 1 Nodes: 1 Job Wall-time: 20 .56% 00 :00:37 of 00 :03:00 time limit CPU Efficiency: 178 .38% 00 :01:06 of 00 :00:37 core-walltime Mem Efficiency: 21 .94% 224 .68 MB of 1 .00 GB slurm profiling \u00b6 Although nn_seff command is a quick and easy way to determine the resource utilisation, it relies on peak values (data gets recorded every 30 seconds) which doesn't allows us to examine resource usage over the run-time of the job. There are number of in-built/external tools to achieve the latter which will require some effort to understand its deployment, tracing and interpretation. Therefore, we will use slurm native profiling to evaluate resource usage over run-time. This is a simple and elegant solution. Exercise 4.4 #Change the working directory to Exercise_4.4 $ cd /nesi/project/nesi02659/sismonr_workshop/workingdir/ $USER /Exercise_4.4 #Run ls command and you should see three files (one .R,sl and one .py - We will discuss the purpose of this .py file after submitting the job) and one directory named slurmout $ ls -F example1_arraysum.R example1_arraysum.sl profile_plot_Jul2020.py slurmout/ #Review the slurm script with cat Or another text editor and submit with sbatch $ sbatch example1_arraysum.sl Do take a note of the JOBID as we are going to need it for next step. Otherwise, we use squeue --me OR sacct command as before to monitor the status Also, you can watch the status of this job via $ watch -n 1 -d \"squeue -j JOBID\" . watch command execute a program periodically, showing output fullscreen. Exiting the watch screen by done by pressing Ctrl+x Let's create slurm profile graphs #collate the data into an HDF5 file using the command. Replace **JOBID** with the corresponding number $ sh5util -j JOBID sh5util: Merging node-step files into ./job_JOBID.h5 #execute the script on .h5 file. We will need one of the Python 3 modules to do this. Ignore the deprecating warning. $ module purge $ module load Python/3.8.2-gimkl-2020a #Replace **JOBID** with the corresponding number $ python profile_plot_Jul2020.py job_JOBID.h5 #This should generate a .png file where the filename is in the format of job_23258404_profile.png Exercise 4.5 \ud83d\ude2c Let's submit your first sismonr slum job. * First step is to copy the already written R script to current working directory #please do make sure the working directory is Exercise_4.5 $ pwd /nesi/project/nesi02659/sismonr_workshop/workingdir/me123/Exercise_4.5 #copy the network file $ cp /nesi/project/nesi02659/sismonr_workshop/dev/slurm_small_sim/simulate_colsystem_1second.R ./ Now build a slurm script with the following parameters We would like the name of the slurm script file to be firstsim_slurm.sl job-name can be anything you want --cpus-per-task 1 and --mem 1G (this is based on test runs) --time 00:12:00 ( we expect the job to run within 10.2 minutes. Let's give it a bit more as runtime can affected by other factors) Give any filename to --out but make sure the .out gets written into slurmout directory Let's add profiling as well. Given the job runs for ~10 minutes, let's leave slurm alone and not ask it to gather data every 1 second. Instead, we will run it with the default 30 second time points .i.e. Don't need a --acctg-freq 1 directive Now to the bash commands section of the slurm script. \ud83d\ude31\ud83d\ude31\ud83d\ude31\ud83d\ude31\ud83d\ude31 export TMPDIR = /nesi/nobackup/nesi02659/tmp/tmp_ $SLURM_JOB_ID mkdir -p $TMPDIR module purge module load sismonr/2.0.0-gimkl-2020a-R-4.1.0 Rscript --vanilla simulate_colsystem_1second.R Back to homepage","title":"4. Working with job scheduler"},{"location":"04_working_with_job_scheduler/#4-working-with-job-scheduler","text":"","title":"4. Working with job scheduler"},{"location":"04_working_with_job_scheduler/#introduction-to-slurm-scheduler-and-directives","text":"An HPC system might have thousands of nodes and thousands of users. How do we decide who gets what and when? How do we ensure that a task is run with the resources it needs? This job is handled by a special piece of software called the scheduler. On an HPC system, the scheduler manages which jobs run where and when. In brief, scheduler is a Mechanism to control access by many users to shared computing resources Queuing / scheduling system for users\u2019 jobs Manages the reservation of resources and job execution on these resources Allows users to \u201cfire and forget\u201d large, long calculations or many jobs (\u201cproduction runs\u201d) Why do we need a scheduler ? To ensure the machine is utilised as fully as possible To ensure all users get a fair chance to use compute resources (demand usually exceeds supply) To track usage - for accounting and budget control To mediate access to other resources e.g. software licences Commonly used schedulers Slurm PBS , Torque Grid Engine LSF \u2013 IBM Systems Researchers can not communicate directly to Compute nodes from the login node. Only way to establish a connection OR send scripts to compute nodes is to use scheduler as the carrier/manager All NeSI clusters use Slurm (Simple Linux Utility for Resource Management) scheduler (or job submission system) to manage resources and how they are made available to users.","title":"Introduction to slurm scheduler and directives"},{"location":"04_working_with_job_scheduler/#life-cycle-of-a-slurm-job","text":"The main commands you will use with Slurm on NeSI Mahuika cluster are: Command Function sbatch Submit non-interactive (batch) jobs to the scheduler squeue List jobs in the queue scancel Cancel a job sacct Display accounting data for all jobs and job steps in the Slurm job accounting log or Slurm database srun Slurm directive for parallel computing sinfo Query the current state of nodes salloc Submit interactive jobs to the scheduler A quick note on sinfo (Query the current state of nodes) which is not a command a researcher will use regularly but helps HPC admins and support staff with monitoring. Exercise 4.1 Let's run the following commands and discuss the outputs #summary of current states of compute nodes known to the scheduler $ sinfo #similar to above but expanded $ sinfo --format = \"%16P %.8m %.5a %10T %.5D %80N\" #will print a long output as it is one row per compute node in the cluster $ sinfo -N -l #Explore the capacity of a compute node $ sinfo -n wch001 -o \"%n %c %m\"","title":"Life cycle of a slurm job"},{"location":"04_working_with_job_scheduler/#anatomy-of-a-slurm-script-and-submitting-first-slurm-job","text":"As with most other scheduler systems, job submission scripts in Slurm consist of a header section with the shell specification and options to the submission command ( sbatch in this case) followed by the body of the script that actually runs the commands you want. In the header section, options to sbatch should be prepended with #SBATCH . Commented lines are ignored by the bash interpreter, but they are not ignored by slurm. The #SBATCH parameters are read by slurm when we submit the job. When the job starts, the bash interpreter will ignore all lines starting with # . This is very similar to the shebang mentioned earlier, when you run your script, the system looks at the #! , then uses the program at the subsequent path to interpret the script, in our case /bin/bash (the program bash found in the /bin directory header use description --job-name #SBATCH --job-name=MyJob The name that will appear when using squeue or sacct. --account #SBATCH --account=nesi12345 The account your core hours will be 'charged' to. --time #SBATCH --time=DD-HH:MM:SS Job max walltime. --mem #SBATCH --mem=512MB Memory required per node. --cpus-per-task #SBATCH --cpus-per-task=10 Will request 10 logical CPUs per task. --output #SBATCH --output=%j_output.out Path and name of standard output file. %j will be replaced by the job ID. --mail-user #SBATCH --mail-user=me23@gmail.com address to send mail notifications. --mail-type #SBATCH --mail-type=ALL Will send a mail notification at BEGIN END FAIL. #SBATCH --mail-type=TIME_LIMIT_80 Will send message at 80% walltime. Exercise 4.2 First create a new working directory and write the script #Change working directory to your personal wd $ cd /nesi/project/nesi02659/sismonr_workshop/workingdir/ $USER #confirm the path is correct (me123 is just a place holder for the place where you should see your username) $ pwd /nesi/project/nesi02659/sismonr_workshop/workingdir/me123/ #create a new directory for this section and change the directory to it $ mkdir Exercise_4.2 && cd Exercise_4.2 #use a text editor of choice to create a file named firstslurm.sl - we will use nano here $ nano firstslurm.sl Content of firstslurm.sl should be as below. Please discuss as you make progress #!/bin/bash #SBATCH --job-name myfirstslurmjob #SBATCH --account nesi02659 #SBATCH --time 00:01:00 #SBATCH --cpus-per-task 1 #SBATCH --mem 512 #SBATCH --output slurmjob.%j.out sleep 40 echo \"I am a slurm job and I slept for 40 seconds\" echo \" $SLURM_JOB_ID END\" Save and Exit Submit the script with sbatch command $ sbatch firstslurm.sl Execute squeue --me and sacct . Discuss the outputs .i.e. $ squeue --me $ sacct","title":"Anatomy of a slurm script and submitting first slurm job \ud83e\uddd0"},{"location":"04_working_with_job_scheduler/#stdoutstderr-from-jobs","text":"STDOUT - your process writes conventional output to this file handle STDERR - your process writes diagnostic output to this file handle. STDOUT and STDERR from jobs are, by default, written to a file called slurm-JOBID.out and slurm-JOBID.err in the working directory for the job (unless the job script changes this, this will be the directory where you submitted the job). So for a job with ID 12345 STDOUT and STDERR would be in slurm-12345.out and slurm-12345.err . When things go wrong, first step of debugging (STORY TIME !) starts with a referral to these files.","title":"STDOUT/STDERR from jobs"},{"location":"04_working_with_job_scheduler/#assessing-resource-utilisation-cpu-memory-time","text":"Understanding the resources you have available and how to use them most efficiently is a vital skill in high performance computing. The three resources that every single job submitted on the platform needs to request are: CPUs (i.e. logical CPU cores), and Memory (RAM), and Time. What happens if I ask for the wrong resources? Resource Asking for too much Not asking for enough Number of CPUs Job may wait in the queue for longer Job will run more slowly than expected, and so may run out time Drop in fairshare score which determines job priority Memory (above) Job will fail, probably with OUT OF MEMORY error, segmentation fault or bus error Wall time (above) Job will run out of time and get killed Exercise 4.3 Let's submit another slurm job and review its resource utilisation #Change the working directory to Exercise_4.3 $ cd /nesi/project/nesi02659/sismonr_workshop/workingdir/ $USER /Exercise_4.3 #Run ls command and you should see two files (one .R and one sl) and one directory named slurmout $ ls -F example1_arraysum.R example1_arraysum.sl slurmout/ #Review the slurm script with cat Or another text editor and submit with sbatch $ sbatch example1_arraysum.sl use squeue --me and sacct again to evaluate the job status Once the job ran into completion, use nn_seff JOBID command to print the resource utilisation statistics (Replace JOBID with the corresponding number) $ nn_seff 23263188 Job ID: 23263188 Cluster: mahuika User/Group: me1234/me123 State: COMPLETED ( exit code 0 ) Cores: 1 Tasks: 1 Nodes: 1 Job Wall-time: 20 .56% 00 :00:37 of 00 :03:00 time limit CPU Efficiency: 178 .38% 00 :01:06 of 00 :00:37 core-walltime Mem Efficiency: 21 .94% 224 .68 MB of 1 .00 GB","title":"Assessing resource utilisation (cpu, memory, time)"},{"location":"04_working_with_job_scheduler/#slurm-profiling","text":"Although nn_seff command is a quick and easy way to determine the resource utilisation, it relies on peak values (data gets recorded every 30 seconds) which doesn't allows us to examine resource usage over the run-time of the job. There are number of in-built/external tools to achieve the latter which will require some effort to understand its deployment, tracing and interpretation. Therefore, we will use slurm native profiling to evaluate resource usage over run-time. This is a simple and elegant solution. Exercise 4.4 #Change the working directory to Exercise_4.4 $ cd /nesi/project/nesi02659/sismonr_workshop/workingdir/ $USER /Exercise_4.4 #Run ls command and you should see three files (one .R,sl and one .py - We will discuss the purpose of this .py file after submitting the job) and one directory named slurmout $ ls -F example1_arraysum.R example1_arraysum.sl profile_plot_Jul2020.py slurmout/ #Review the slurm script with cat Or another text editor and submit with sbatch $ sbatch example1_arraysum.sl Do take a note of the JOBID as we are going to need it for next step. Otherwise, we use squeue --me OR sacct command as before to monitor the status Also, you can watch the status of this job via $ watch -n 1 -d \"squeue -j JOBID\" . watch command execute a program periodically, showing output fullscreen. Exiting the watch screen by done by pressing Ctrl+x Let's create slurm profile graphs #collate the data into an HDF5 file using the command. Replace **JOBID** with the corresponding number $ sh5util -j JOBID sh5util: Merging node-step files into ./job_JOBID.h5 #execute the script on .h5 file. We will need one of the Python 3 modules to do this. Ignore the deprecating warning. $ module purge $ module load Python/3.8.2-gimkl-2020a #Replace **JOBID** with the corresponding number $ python profile_plot_Jul2020.py job_JOBID.h5 #This should generate a .png file where the filename is in the format of job_23258404_profile.png Exercise 4.5 \ud83d\ude2c Let's submit your first sismonr slum job. * First step is to copy the already written R script to current working directory #please do make sure the working directory is Exercise_4.5 $ pwd /nesi/project/nesi02659/sismonr_workshop/workingdir/me123/Exercise_4.5 #copy the network file $ cp /nesi/project/nesi02659/sismonr_workshop/dev/slurm_small_sim/simulate_colsystem_1second.R ./ Now build a slurm script with the following parameters We would like the name of the slurm script file to be firstsim_slurm.sl job-name can be anything you want --cpus-per-task 1 and --mem 1G (this is based on test runs) --time 00:12:00 ( we expect the job to run within 10.2 minutes. Let's give it a bit more as runtime can affected by other factors) Give any filename to --out but make sure the .out gets written into slurmout directory Let's add profiling as well. Given the job runs for ~10 minutes, let's leave slurm alone and not ask it to gather data every 1 second. Instead, we will run it with the default 30 second time points .i.e. Don't need a --acctg-freq 1 directive Now to the bash commands section of the slurm script. \ud83d\ude31\ud83d\ude31\ud83d\ude31\ud83d\ude31\ud83d\ude31 export TMPDIR = /nesi/nobackup/nesi02659/tmp/tmp_ $SLURM_JOB_ID mkdir -p $TMPDIR module purge module load sismonr/2.0.0-gimkl-2020a-R-4.1.0 Rscript --vanilla simulate_colsystem_1second.R Back to homepage","title":"slurm profiling"},{"location":"05_parallel_job_arrays/","text":"5. Parallel Job Arrays \u00b6 Introduction to parallel computing \u00b6 STORY TIME ! Many scientific software applications are written to take advantage of multiple CPUs in some way. But often this must be specifically requested by the user at the time they run the program, rather than happening automatically. The scheduler provides the simplest method for running parallel computations. SLURM schedules thousands of simultaneous calculations on NeSI clusters and will gladly execute many of your jobs at once, as long as there are available resources. This means, that in contrast to the language-specific parallelism methods required by shared memory ( OpenMP, etc. \ud83d\ude15), distributed memory (MPI,etc. \ud83d\ude35\u200d\ud83d\udcab), and various threading methods built into languages like Python, Matlab, and R, slurm can provide embarassingly parallel calculations. These calculations, more generously called \u201cperfectly parallel\u201d do not require any exchange of information between individual jobs which would otherwise require a high-speed network and intelligent algorithm for communicating these data. (\ud83e\udd14) They scale perfectly which means that twice as much calculation can be completed in the same amount of time with twice as much hardware. This is not always true for true or imperfect parallel calculations \ud83d\ude08 Shared memory, Distributed memory, OpenMP, MPI ? ....none of these terms are associated with Gene Regulation \ud83d\ude20 Correct & not having an in-depth knowledge on these topics will not affect the end goal of this workshop Okay, so we just call it witchcraft or black magic and move on ? \ud83e\uddd9\u200d\u2640\ufe0f Yes we can \ud83e\udd73 However, If you are writing a custom R, Julia or Python library for simulations (or for another purpose which requires scaling), those specifications will assist you with making the library more efficient and reliable \ud83e\udd13 Shared memory vs Distributed memory (Optional) Shared memory Distributed memory In a shared memory model all processors have access to a pool of common memory that they can freely use. In a distributed memory model a separate segment of memory is available to each processor. Because memory isn\u2019t shared inherently, information that must be shared between processes is sent over a network. Let's break this down a bit by using the schematic use for illustrating HPC architecture Analogy * Shared memory: * One very large whiteboard in a two-person office (the shared memory) * Two people working on the same problem (threads running on different cores attached to the memory) * How do they collaborate (working together but not interfering) * need private data Distributed memory Two whiteboards in different single-person offices (distributed memory) Two people working on the same problem (processes on different nodes attached to the interconnect) How do they collaborate (to work on a single problem) Explicit communication (for example by phone. Also, no shared data) Multi-threading (Optional) Multi-threading is a method of parallelisation whereby the initial single thread of a process forks into a number of parallel threads, generally via a library such as OpenMP (Open MultiProcessing), TBB (Threading Building Blocks), or pthread (POSIX threads). Let's take a look at the difference between a serial job and a multi-threaded job Exercise 5.1 Let's try out a multi-threading example script with OpenMP which is an application programming interface that supports multi-platform shared-memory #confirm the working directory $ pwd /nesi/project/nesi02659/sismonr_workshop/workingdir/me123/ #create a new directory for this episode, cd into it $ mkdir 5_parallel && cd 5_parallel #Create two more working directories for this exercise and the next one and change to `openmp` directory $ mkdir { openmp,mpi } && cd openmp #Copy the pre-compiled `omp_helloworld` to current working directory $ cp /nesi/project/nesi02659/sismonr_workshop/dev/openmp/omp_helloworld ./ #use a text editor of choice to create a file named openmp_hw.sl - we will use nano here $ nano openmp_hw.sl Content of openmp_hw.sl is as below #!/bin/bash #SBATCH --account nesi02659 #SBATCH --job-name openmp_helloworld #SBATCH --cpus-per-task 6 #SBATCH --mem-per-cpu 100 #SBATCH --output openmp_hw_%j.out module purge export OMP_NUM_THREADS = ${ SLURM_CPUS_PER_TASK } srun ./omp_helloworld Explanation Slurm by default doesn\u2019t know what cores to assign to what process it runs. For threaded applications, you need to make sure that all the cores you request are on the same node. The OpenMP script is an example that all the cores are on the same node, and lets Slurm know which process gets the cores that you requested for threading. OMP_NUM_THREADS environment variable is used to specify the default number of threads to use in parallel regions. By adjusting the value of the OMP_NUM_THREADS environment variable, one can adjust the number of execution threads. Submit the script with sbatch openmp_hw.sl and review the content of .out file openmp_hw_jobid.out upon completion .i.e. $ sbatch openmp_hw.sl MPI (Message Passing Interface) - (Optional) MPI is a specification for the developers and users of message passing libraries. By itself, it is NOT a library - but rather the specification of what such a library should be. MPI primarily addresses the message-passing parallel programming model: data is moved from the address space of one process to that of another process through cooperative operations on each process. Simply stated, the goal of the Message Passing Interface is to provide a widely used standard for writing message passing programs. The interface attempts to be: Practical Portable Efficient Flexible Exercise 5.2 Let's try out a MPI example #make sure you have changed the current working directory to 5_parallel/mpi $ pwd /nesi/project/nesi02659/sismonr_workshop/workingdir/me123/5_parallel/mpi #copy the pre-compiled mpi program to current working directory $ cp /nesi/project/nesi02659/sismonr_workshop/dev/mpi/mpi_helloworld ./ #use a text editor of choice to create a file named mpi_hw.sl - we will use nano here $ nano mpi_hw.sl Content of mpi_hw.sl is as below #!/bin/bash #SBATCH --account nesi02659 #SBATCH --job-name mpi_helloworld #SBATCH --cpus-per-task 1 #SBATCH --ntasks 6 #SBATCH --nodes 2 #SBATCH --mem-per-cpu 100 #SBATCH --output mpi_hw_%j.out module purge && module load OpenMPI/4.1.1-GCC-9.2.0 srun ./mpi_helloworld Explanation srun command executes the program. The --ntasks is the number of MPI processes to run. The script executed 6 processes and the incremented integer values in .out file will show the communication between the processes. These proocesses will be distributed across two compute nodes ( --nodes 2 ). Submit the script with sbatch mpi_hw.sl and review the content of .out file mpi_hw_jobid.out upon completion .i.e. bash $ sbatch mpi_hw.sl NOTE : .out file will print 6 x Hello world from processor wbn125, rank 4 out of 6 processors message (or something along those lines) wbn125 - this is the compute node ID. It will be different for everyone as we have hundreds of compute nodes and this job will land on two ( --nodes 2 ) out of those hundreds. processor - actual instance of the program that are running rank - MPI allows you to create logical groups of processes, and in each group, a process is identified by its rank . This is an integer in the range of [0,N-1] where N is the size of the group. In general, there are two advantages to running applications in parallel: (1) applications will run more quickly and we can get our solutions faster, and (2) we can solve larger, more complex problems.In an ideal world, if we increase the number of cores we are using by a factor of 10, we should be able to either get the solution to our current problem 10 times faster, or to run a system 10 times bigger in the same amount of time as now. Unfortunately, this is often not the case\u2026 Strong vs. weak scaling \u00b6 Scaling describes how the runtime of a parallel application changes as the number of processors is increased. Usually, there are two types of scaling of interest: strong scaling is obtained by increasing the number of processors P used for a problem of fixed size/complexity N. As the number of processors increases, the amount of work per processor should decrease. weak scaling is obtained by increasing both the number of processors and the system size/complexity, with both of these being increased at the same rate. Ideally, for strong scaling, the runtime will keep decreasing in direct proportion to the growing number of processors used. For weak scaling, the ideal situation is for the runtime to remain constant as the system size, and number of processors used, are increased. In general, good strong scaling is more relevant for most scientific problems, but is also more difficult to achieve than weak scaling. Amdhal\u2019s law and strong scaling Gustafson\u2019s law and weak scaling Definition Analogy The limitations of strong scaling are best illustrated by Amdhal\u2019s law: \u201cThe performance improvement to be gained by parallelisation is limited by the proportion of the code which is serial\u201d. As more processors are used, the runtime becomes more and more dominated by the serial portion of a code. Consider a trip from Edinburgh to the Empire State building in New York. The distance from Edinburgh to New York is 5,200 km , and you can either fly with a Jumbo Jet (flight speed 700 km/hr ) or a Concorde (flight speed 2,100 km/hr ). What is the speedup of using the Concorde? Answer The Jumbo Jet will cover that distance in around 7h30 , and the Concorde covers this in 2h00 , so you might think that the speedup is 3.75x . However , in this problem, we are not starting in a plane about to take off! There are additional times to take into consideration: Trip to Edinburgh airport: 30 mins Security and boarding: 1h30 US immigrations: 1h00 Taxi ride to downtown New York: 1h00 There is a fixed overhead of 4 hrs that we can\u2019t reduce. When considering this 4-hour overhead, we find that our total trip by Jumbo Jet takes 11h30 , whereas travelling by Concorde takes 6 hrs . Our speedup is therefore 1.92x not 3.75x . Amdhal\u2019s law suggests that, the shorter the journey, the more important the fixed (serial) overhead is in determining the total journey time. Definition Analogy Gustafson\u2019s law provides a solution to the limitations of strong scaling described. The proposal is simply: we should run larger jobs on larger processor counts. If we run larger problems, then the parallelisable part of the problem will increase. We are still limited by the serial part of the code, but this becomes less important, and we can run on more processors more efficiently. Let\u2019s consider a new trip, one from Edinburgh to the Sydney Opera House in Australia. The distance from Edinburgh to Sydney is 16,800 km . As with our trip to New York, you can either fly with a Jumbo Jet (flight speed 700 km/hr ) or a Concorde (flight speed 2,100 km/hr ). Also, let\u2019s assume that the overhead is similar to that for a trip to New York (so 4 hours). What is the speedup of using the Concorde this time? Answer The Jumbo Jet will cover that distance in around 24 hrs for a total trip time of 28 hrs , and the Concorde covers this distance in 8hrs for a total trip time of 12 hrs . The speedup is therefor 2.3x (as opposed to 1.9x for the trip to New York). This is Gustafson\u2019s law in effect! Bigger problems scale better. If we increase both distance (i.e. \\(N\\) ) and maximum speed (i.e. \\(P\\) ), we maintain the same balance of \u201cserials\u201d to \u201cparallel\u201d, and get a better speedup. Load imbalance \u00b6 The laws and thoughts above only apply to cases where all processors are equally busy. What happens if some processors run out of work while others are still busy? Scalibility isn\u2019t everything! It\u2019s also important to make the best use of all processors at hand before increasing the number of processors. Slurm job arrays \u00b6 Job arrays offer a mechanism for submitting and managing collections of similar jobs quickly and easily; job arrays with millions of tasks can be submitted in milliseconds (subject to configured size limits). All jobs must have the same initial options (e.g. size, time limit, etc.) In brief, Job arrays allow you to leverage Slurm\u2019s ability to create multiple jobs from one script. Many of the situations where this is useful include: Establishing a list of commands to run and have a job created from each command in the list. Running many parameters against one set of data or analysis program. Running the same program multiple times with different sets of data. Exercise 5.3 Let's start compiling our first slurm array script Purpose is to execute the same sleep 40 command we used in Working with job scheduler episode but we want to run five iterations of it #Change the working directory to Exercise_5.3 $ cd /nesi/project/nesi02659/sismonr_workshop/workingdir/ $USER /Exercise_5.3 #You should see a single .sl and a directory named slurmout $ ls -F firstslurm_array.sl slurmout/ Content of firstslurm_array.sl should be as below. Please discuss as you make progress #!/bin/bash -e #SBATCH --account nesi02659 #SBATCH --job-name first_slurm_Array #SBATCH --time 00:02:30 #SBATCH --output slurmout/sleeparray.%A.%a.out #SBATCH --cpus-per-task 1 #SBATCH --mem 100 #SBATCH --array 1-5 ###Some Jupyter specific variabes to submit srun commands from Jupyter Terminal srun sleep 120 echo \"I am a slurm job and I slept for 120 seconds but this time in Parallel\" echo \"This is the result for ${ SLURM_ARRAY_TASK_ID } \" Let's review some of those new slurm directives and variables prior to submitting the script Job arrays are only supported for batch jobs and the array index values are specified using the --array or -a option. This is the most important directive in an array script .out filename %A and %a where : %A will be replaced by the value of SLURM_ARRAY_JOB_ID (will be set to the first job ID of the array) and %a will be replaced by the value of SLURM_ARRAY_TASK_ID (will be set to the job array index value). Let's review the meaning of these two variables after submitting the job Once you submit the job with sbatch firstslurm_array.sl , take a note of the jobid and run the command squeue -j jobid . For an example, let's use the hypothetical job id 23284978 and view the output $ squeue -j 23284978 JOBID USER ACCOUNT NAME CPUS MIN_MEM PARTITI START_TIME TIME_LEFT STATE NODELIST ( REASON ) 23284978_1 me123 nesi02659 first_slurm_ 2 100M large Nov 28 09 :26 0 :57 RUNNING wbn094 23284978_2 me123 nesi02659 first_slurm_ 2 100M large Nov 28 09 :26 0 :57 RUNNING wbn094 23284978_3 me123 nesi02659 first_slurm_ 2 100M large Nov 28 09 :26 0 :57 RUNNING wbn096 23284978_4 me123 nesi02659 first_slurm_ 2 100M large Nov 28 09 :26 0 :57 RUNNING wbn096 23284978_5 me123 nesi02659 first_slurm_ 2 100M large Nov 28 09 :26 0 :57 RUNNING wbn096 Once the job is completed, take a look at the slurmout/ directory. There should be 5 x .out files Exercise 5.4 Objective of this exercise is to to run slurm array with two indexes each running 2 simulations. #Change working directory to Exercise_5.4 $ cd /nesi/project/nesi02659/sismonr_workshop/workingdir/ $USER /Exercise_5.4 #Run ls command you should 2 files and a directory named slurmout $ ls -F 250sims_2arrayindex.sl simulate_colsystem_array_2sim.R slurmout/ #use cat command to view the content of slurm script 250sims_2arrayindex.sl(or open it via nano, vim or another text editor) $ cat 250sims_2arrayindex.sl Let's review some of those new slurm directives and variables prior to submitting the script Job arrays are only supported for batch jobs and the array index values are specified using the --array or -a option. This is the most important directive in an array script .out filename %A and %a where : %A will be replaced by the value of SLURM_ARRAY_JOB_ID (will be set to the first job ID of the array) and %a will be replaced by the value of SLURM_ARRAY_TASK_ID (will be set to the job array index value). Let's review the meaning of these two variables after submitting the job Content of 250sims_2arrayindex.sl should be as below. Please discuss as you make progress #!/bin/bash -e #SBATCH --account nesi02659 #SBATCH --job-name simulations_250_test #SBATCH --time 00:15:00 #SBATCH --mem 2GB #SBATCH --cpus-per-task 2 #SBATCH --array 1-2 #SBATCH --output slurmout/sims_250_test_%A_%a.out # Include the array ID in the names of #SBATCH --error slurmout/sims_250_test_%A_%a.err # the output and error files ###Some processes can generate temporary files which can be redirected from RAM memory to scratch(nobackup) to reduce the Memory footprint export TMPDIR = /nesi/nobackup/nesi02659/tmp/tmp_ ${ SLURM_JOB_ID } _ ${ SLURM_ARRAY_TASK_ID } mkdir -p $TMPDIR #Sismonr specific variable export GROUP_ID = 1 module purge module load sismonr/2.0.0-gimkl-2020a-R-4.1.0 srun Rscript simulate_colsystem_array_2sim.R Submit the script with sbatch 250sims_2arrayindex.sl , take a not on the jobid and run the command squeue -j jobid . Take a look at the content of .out and .err files in slurmout directory If all goes well, job should run within 10 minutes and will generate two .rds files in current working directory .i.e. Exercise_5.4 simulation_1_group1.rds simulation_2_group1.rds Exercise 5.5 (Group) Host will assign you to a breakout room (zoom) or a group. Given the time constraint and the amount of resources required to run all of the simulations, each group will submit a single array job with 250 indexes. Start with changing the working directory to Exercise_5.5 As a group, write a slurm script based on 250sims_2arrayindex.sl from Exercise 5.4 to run 250 arrays. Also, don't forget that you do need a copy of the simulate_colsystem_array_2sim.R in current workig directory (OR use the relative/absolute path of working directory from previous exercise) Double check...Triple check before submission. \ud83d\ude42 Then, choose one person in the group who will submit the job. The simulations output should be created in the working directory of the person who submitted the job. In the next section, the other members of the group will have to copy these output files for the post-processing step.(Or the instructors will provide a copy for you) Back to homepage","title":"5. Parallel Job Arrays"},{"location":"05_parallel_job_arrays/#5-parallel-job-arrays","text":"","title":"5. Parallel Job Arrays"},{"location":"05_parallel_job_arrays/#introduction-to-parallel-computing","text":"STORY TIME ! Many scientific software applications are written to take advantage of multiple CPUs in some way. But often this must be specifically requested by the user at the time they run the program, rather than happening automatically. The scheduler provides the simplest method for running parallel computations. SLURM schedules thousands of simultaneous calculations on NeSI clusters and will gladly execute many of your jobs at once, as long as there are available resources. This means, that in contrast to the language-specific parallelism methods required by shared memory ( OpenMP, etc. \ud83d\ude15), distributed memory (MPI,etc. \ud83d\ude35\u200d\ud83d\udcab), and various threading methods built into languages like Python, Matlab, and R, slurm can provide embarassingly parallel calculations. These calculations, more generously called \u201cperfectly parallel\u201d do not require any exchange of information between individual jobs which would otherwise require a high-speed network and intelligent algorithm for communicating these data. (\ud83e\udd14) They scale perfectly which means that twice as much calculation can be completed in the same amount of time with twice as much hardware. This is not always true for true or imperfect parallel calculations \ud83d\ude08 Shared memory, Distributed memory, OpenMP, MPI ? ....none of these terms are associated with Gene Regulation \ud83d\ude20 Correct & not having an in-depth knowledge on these topics will not affect the end goal of this workshop Okay, so we just call it witchcraft or black magic and move on ? \ud83e\uddd9\u200d\u2640\ufe0f Yes we can \ud83e\udd73 However, If you are writing a custom R, Julia or Python library for simulations (or for another purpose which requires scaling), those specifications will assist you with making the library more efficient and reliable \ud83e\udd13 Shared memory vs Distributed memory (Optional) Shared memory Distributed memory In a shared memory model all processors have access to a pool of common memory that they can freely use. In a distributed memory model a separate segment of memory is available to each processor. Because memory isn\u2019t shared inherently, information that must be shared between processes is sent over a network. Let's break this down a bit by using the schematic use for illustrating HPC architecture Analogy * Shared memory: * One very large whiteboard in a two-person office (the shared memory) * Two people working on the same problem (threads running on different cores attached to the memory) * How do they collaborate (working together but not interfering) * need private data Distributed memory Two whiteboards in different single-person offices (distributed memory) Two people working on the same problem (processes on different nodes attached to the interconnect) How do they collaborate (to work on a single problem) Explicit communication (for example by phone. Also, no shared data) Multi-threading (Optional) Multi-threading is a method of parallelisation whereby the initial single thread of a process forks into a number of parallel threads, generally via a library such as OpenMP (Open MultiProcessing), TBB (Threading Building Blocks), or pthread (POSIX threads). Let's take a look at the difference between a serial job and a multi-threaded job Exercise 5.1 Let's try out a multi-threading example script with OpenMP which is an application programming interface that supports multi-platform shared-memory #confirm the working directory $ pwd /nesi/project/nesi02659/sismonr_workshop/workingdir/me123/ #create a new directory for this episode, cd into it $ mkdir 5_parallel && cd 5_parallel #Create two more working directories for this exercise and the next one and change to `openmp` directory $ mkdir { openmp,mpi } && cd openmp #Copy the pre-compiled `omp_helloworld` to current working directory $ cp /nesi/project/nesi02659/sismonr_workshop/dev/openmp/omp_helloworld ./ #use a text editor of choice to create a file named openmp_hw.sl - we will use nano here $ nano openmp_hw.sl Content of openmp_hw.sl is as below #!/bin/bash #SBATCH --account nesi02659 #SBATCH --job-name openmp_helloworld #SBATCH --cpus-per-task 6 #SBATCH --mem-per-cpu 100 #SBATCH --output openmp_hw_%j.out module purge export OMP_NUM_THREADS = ${ SLURM_CPUS_PER_TASK } srun ./omp_helloworld Explanation Slurm by default doesn\u2019t know what cores to assign to what process it runs. For threaded applications, you need to make sure that all the cores you request are on the same node. The OpenMP script is an example that all the cores are on the same node, and lets Slurm know which process gets the cores that you requested for threading. OMP_NUM_THREADS environment variable is used to specify the default number of threads to use in parallel regions. By adjusting the value of the OMP_NUM_THREADS environment variable, one can adjust the number of execution threads. Submit the script with sbatch openmp_hw.sl and review the content of .out file openmp_hw_jobid.out upon completion .i.e. $ sbatch openmp_hw.sl MPI (Message Passing Interface) - (Optional) MPI is a specification for the developers and users of message passing libraries. By itself, it is NOT a library - but rather the specification of what such a library should be. MPI primarily addresses the message-passing parallel programming model: data is moved from the address space of one process to that of another process through cooperative operations on each process. Simply stated, the goal of the Message Passing Interface is to provide a widely used standard for writing message passing programs. The interface attempts to be: Practical Portable Efficient Flexible Exercise 5.2 Let's try out a MPI example #make sure you have changed the current working directory to 5_parallel/mpi $ pwd /nesi/project/nesi02659/sismonr_workshop/workingdir/me123/5_parallel/mpi #copy the pre-compiled mpi program to current working directory $ cp /nesi/project/nesi02659/sismonr_workshop/dev/mpi/mpi_helloworld ./ #use a text editor of choice to create a file named mpi_hw.sl - we will use nano here $ nano mpi_hw.sl Content of mpi_hw.sl is as below #!/bin/bash #SBATCH --account nesi02659 #SBATCH --job-name mpi_helloworld #SBATCH --cpus-per-task 1 #SBATCH --ntasks 6 #SBATCH --nodes 2 #SBATCH --mem-per-cpu 100 #SBATCH --output mpi_hw_%j.out module purge && module load OpenMPI/4.1.1-GCC-9.2.0 srun ./mpi_helloworld Explanation srun command executes the program. The --ntasks is the number of MPI processes to run. The script executed 6 processes and the incremented integer values in .out file will show the communication between the processes. These proocesses will be distributed across two compute nodes ( --nodes 2 ). Submit the script with sbatch mpi_hw.sl and review the content of .out file mpi_hw_jobid.out upon completion .i.e. bash $ sbatch mpi_hw.sl NOTE : .out file will print 6 x Hello world from processor wbn125, rank 4 out of 6 processors message (or something along those lines) wbn125 - this is the compute node ID. It will be different for everyone as we have hundreds of compute nodes and this job will land on two ( --nodes 2 ) out of those hundreds. processor - actual instance of the program that are running rank - MPI allows you to create logical groups of processes, and in each group, a process is identified by its rank . This is an integer in the range of [0,N-1] where N is the size of the group. In general, there are two advantages to running applications in parallel: (1) applications will run more quickly and we can get our solutions faster, and (2) we can solve larger, more complex problems.In an ideal world, if we increase the number of cores we are using by a factor of 10, we should be able to either get the solution to our current problem 10 times faster, or to run a system 10 times bigger in the same amount of time as now. Unfortunately, this is often not the case\u2026","title":"Introduction to parallel computing"},{"location":"05_parallel_job_arrays/#strong-vs-weak-scaling","text":"Scaling describes how the runtime of a parallel application changes as the number of processors is increased. Usually, there are two types of scaling of interest: strong scaling is obtained by increasing the number of processors P used for a problem of fixed size/complexity N. As the number of processors increases, the amount of work per processor should decrease. weak scaling is obtained by increasing both the number of processors and the system size/complexity, with both of these being increased at the same rate. Ideally, for strong scaling, the runtime will keep decreasing in direct proportion to the growing number of processors used. For weak scaling, the ideal situation is for the runtime to remain constant as the system size, and number of processors used, are increased. In general, good strong scaling is more relevant for most scientific problems, but is also more difficult to achieve than weak scaling. Amdhal\u2019s law and strong scaling Gustafson\u2019s law and weak scaling Definition Analogy The limitations of strong scaling are best illustrated by Amdhal\u2019s law: \u201cThe performance improvement to be gained by parallelisation is limited by the proportion of the code which is serial\u201d. As more processors are used, the runtime becomes more and more dominated by the serial portion of a code. Consider a trip from Edinburgh to the Empire State building in New York. The distance from Edinburgh to New York is 5,200 km , and you can either fly with a Jumbo Jet (flight speed 700 km/hr ) or a Concorde (flight speed 2,100 km/hr ). What is the speedup of using the Concorde? Answer The Jumbo Jet will cover that distance in around 7h30 , and the Concorde covers this in 2h00 , so you might think that the speedup is 3.75x . However , in this problem, we are not starting in a plane about to take off! There are additional times to take into consideration: Trip to Edinburgh airport: 30 mins Security and boarding: 1h30 US immigrations: 1h00 Taxi ride to downtown New York: 1h00 There is a fixed overhead of 4 hrs that we can\u2019t reduce. When considering this 4-hour overhead, we find that our total trip by Jumbo Jet takes 11h30 , whereas travelling by Concorde takes 6 hrs . Our speedup is therefore 1.92x not 3.75x . Amdhal\u2019s law suggests that, the shorter the journey, the more important the fixed (serial) overhead is in determining the total journey time. Definition Analogy Gustafson\u2019s law provides a solution to the limitations of strong scaling described. The proposal is simply: we should run larger jobs on larger processor counts. If we run larger problems, then the parallelisable part of the problem will increase. We are still limited by the serial part of the code, but this becomes less important, and we can run on more processors more efficiently. Let\u2019s consider a new trip, one from Edinburgh to the Sydney Opera House in Australia. The distance from Edinburgh to Sydney is 16,800 km . As with our trip to New York, you can either fly with a Jumbo Jet (flight speed 700 km/hr ) or a Concorde (flight speed 2,100 km/hr ). Also, let\u2019s assume that the overhead is similar to that for a trip to New York (so 4 hours). What is the speedup of using the Concorde this time? Answer The Jumbo Jet will cover that distance in around 24 hrs for a total trip time of 28 hrs , and the Concorde covers this distance in 8hrs for a total trip time of 12 hrs . The speedup is therefor 2.3x (as opposed to 1.9x for the trip to New York). This is Gustafson\u2019s law in effect! Bigger problems scale better. If we increase both distance (i.e. \\(N\\) ) and maximum speed (i.e. \\(P\\) ), we maintain the same balance of \u201cserials\u201d to \u201cparallel\u201d, and get a better speedup.","title":"Strong vs. weak scaling"},{"location":"05_parallel_job_arrays/#load-imbalance","text":"The laws and thoughts above only apply to cases where all processors are equally busy. What happens if some processors run out of work while others are still busy? Scalibility isn\u2019t everything! It\u2019s also important to make the best use of all processors at hand before increasing the number of processors.","title":"Load imbalance"},{"location":"05_parallel_job_arrays/#slurm-job-arrays","text":"Job arrays offer a mechanism for submitting and managing collections of similar jobs quickly and easily; job arrays with millions of tasks can be submitted in milliseconds (subject to configured size limits). All jobs must have the same initial options (e.g. size, time limit, etc.) In brief, Job arrays allow you to leverage Slurm\u2019s ability to create multiple jobs from one script. Many of the situations where this is useful include: Establishing a list of commands to run and have a job created from each command in the list. Running many parameters against one set of data or analysis program. Running the same program multiple times with different sets of data. Exercise 5.3 Let's start compiling our first slurm array script Purpose is to execute the same sleep 40 command we used in Working with job scheduler episode but we want to run five iterations of it #Change the working directory to Exercise_5.3 $ cd /nesi/project/nesi02659/sismonr_workshop/workingdir/ $USER /Exercise_5.3 #You should see a single .sl and a directory named slurmout $ ls -F firstslurm_array.sl slurmout/ Content of firstslurm_array.sl should be as below. Please discuss as you make progress #!/bin/bash -e #SBATCH --account nesi02659 #SBATCH --job-name first_slurm_Array #SBATCH --time 00:02:30 #SBATCH --output slurmout/sleeparray.%A.%a.out #SBATCH --cpus-per-task 1 #SBATCH --mem 100 #SBATCH --array 1-5 ###Some Jupyter specific variabes to submit srun commands from Jupyter Terminal srun sleep 120 echo \"I am a slurm job and I slept for 120 seconds but this time in Parallel\" echo \"This is the result for ${ SLURM_ARRAY_TASK_ID } \" Let's review some of those new slurm directives and variables prior to submitting the script Job arrays are only supported for batch jobs and the array index values are specified using the --array or -a option. This is the most important directive in an array script .out filename %A and %a where : %A will be replaced by the value of SLURM_ARRAY_JOB_ID (will be set to the first job ID of the array) and %a will be replaced by the value of SLURM_ARRAY_TASK_ID (will be set to the job array index value). Let's review the meaning of these two variables after submitting the job Once you submit the job with sbatch firstslurm_array.sl , take a note of the jobid and run the command squeue -j jobid . For an example, let's use the hypothetical job id 23284978 and view the output $ squeue -j 23284978 JOBID USER ACCOUNT NAME CPUS MIN_MEM PARTITI START_TIME TIME_LEFT STATE NODELIST ( REASON ) 23284978_1 me123 nesi02659 first_slurm_ 2 100M large Nov 28 09 :26 0 :57 RUNNING wbn094 23284978_2 me123 nesi02659 first_slurm_ 2 100M large Nov 28 09 :26 0 :57 RUNNING wbn094 23284978_3 me123 nesi02659 first_slurm_ 2 100M large Nov 28 09 :26 0 :57 RUNNING wbn096 23284978_4 me123 nesi02659 first_slurm_ 2 100M large Nov 28 09 :26 0 :57 RUNNING wbn096 23284978_5 me123 nesi02659 first_slurm_ 2 100M large Nov 28 09 :26 0 :57 RUNNING wbn096 Once the job is completed, take a look at the slurmout/ directory. There should be 5 x .out files Exercise 5.4 Objective of this exercise is to to run slurm array with two indexes each running 2 simulations. #Change working directory to Exercise_5.4 $ cd /nesi/project/nesi02659/sismonr_workshop/workingdir/ $USER /Exercise_5.4 #Run ls command you should 2 files and a directory named slurmout $ ls -F 250sims_2arrayindex.sl simulate_colsystem_array_2sim.R slurmout/ #use cat command to view the content of slurm script 250sims_2arrayindex.sl(or open it via nano, vim or another text editor) $ cat 250sims_2arrayindex.sl Let's review some of those new slurm directives and variables prior to submitting the script Job arrays are only supported for batch jobs and the array index values are specified using the --array or -a option. This is the most important directive in an array script .out filename %A and %a where : %A will be replaced by the value of SLURM_ARRAY_JOB_ID (will be set to the first job ID of the array) and %a will be replaced by the value of SLURM_ARRAY_TASK_ID (will be set to the job array index value). Let's review the meaning of these two variables after submitting the job Content of 250sims_2arrayindex.sl should be as below. Please discuss as you make progress #!/bin/bash -e #SBATCH --account nesi02659 #SBATCH --job-name simulations_250_test #SBATCH --time 00:15:00 #SBATCH --mem 2GB #SBATCH --cpus-per-task 2 #SBATCH --array 1-2 #SBATCH --output slurmout/sims_250_test_%A_%a.out # Include the array ID in the names of #SBATCH --error slurmout/sims_250_test_%A_%a.err # the output and error files ###Some processes can generate temporary files which can be redirected from RAM memory to scratch(nobackup) to reduce the Memory footprint export TMPDIR = /nesi/nobackup/nesi02659/tmp/tmp_ ${ SLURM_JOB_ID } _ ${ SLURM_ARRAY_TASK_ID } mkdir -p $TMPDIR #Sismonr specific variable export GROUP_ID = 1 module purge module load sismonr/2.0.0-gimkl-2020a-R-4.1.0 srun Rscript simulate_colsystem_array_2sim.R Submit the script with sbatch 250sims_2arrayindex.sl , take a not on the jobid and run the command squeue -j jobid . Take a look at the content of .out and .err files in slurmout directory If all goes well, job should run within 10 minutes and will generate two .rds files in current working directory .i.e. Exercise_5.4 simulation_1_group1.rds simulation_2_group1.rds Exercise 5.5 (Group) Host will assign you to a breakout room (zoom) or a group. Given the time constraint and the amount of resources required to run all of the simulations, each group will submit a single array job with 250 indexes. Start with changing the working directory to Exercise_5.5 As a group, write a slurm script based on 250sims_2arrayindex.sl from Exercise 5.4 to run 250 arrays. Also, don't forget that you do need a copy of the simulate_colsystem_array_2sim.R in current workig directory (OR use the relative/absolute path of working directory from previous exercise) Double check...Triple check before submission. \ud83d\ude42 Then, choose one person in the group who will submit the job. The simulations output should be created in the working directory of the person who submitted the job. In the next section, the other members of the group will have to copy these output files for the post-processing step.(Or the instructors will provide a copy for you) Back to homepage","title":"Slurm job arrays"},{"location":"06_post_processing/","text":"6. Post-processing \u00b6 Checking that the job array worked \u00b6 In the previous section, you have seen how to run a slurm array job. Now it is time to check whether the arrays completed without failing! And if some of the arrays did fail, we would like to identify them to re-run them. As we have seen in the previous sections, the sacct command is useful to assess the status of submitted jobs. However, especially if you have many arrays, it can get difficult to find what you are looking for in the output. Fortunately, there is a (rather lengthy) command which allows you to obtain the ID of the arrays that failed in a format compatible with slurm. The advantage is that you can directly copy the output of this command and paste it in your slurm script for the array option, in order to re-run only those arrays that failed. Type the following command in the terminal: $ sacct -j $JOB_ID -X -n -s TO,F,OOM -o jobid | cut -d \"_\" -f2 | tr -s ' \\n' ',' In the command, you'll need to replace $JOB_ID by your actual slurm job ID. Your turn! Did any of your arrays failed? If so, what would you change before re-running them? Index TO = Timed Out F = Failed OOM = Out Of Memory Interpreting the sismonr output \u00b6 Now, it is time to analyse the simulations that we generated. Copying the simulation outputs to relevant directory \u00b6 In the simulation script, we made sure to save each simulation into a .RData file. First, make sure that you are in the appropriate directory by typing in the terminal: $ pwd /nesi/project/nesi02659/sismonr_workshop/workingdir/me123/Exercise_5.5 If you do not have results, you can copy the backup files with: $ cp /nesi/project/nesi02659/sismonr_workshop/backup_simulations/simulation_* /nesi/project/nesi02659/sismonr_workshop/workingdir/me123/Exercise_5.5/ of course replacing me123 with your own username. Looking at one simulation output \u00b6 Start a new sismonr Jupyter Notebook in the folder containing the simulations output. In the first cell, add and execute: library ( sismonr ) library ( tibble ) library ( dplyr ) library ( stringr ) library ( purrr ) library ( ggplot2 ) A single .rds file can be then loaded into R with: sim <- readRDS ( \"simulation_1_group1.RData\" ) The output of sismonr is a list composed of 3 elements: Simulation : a data-frame with the simulation results. Columns time , Ind and trial indicate the time (in seconds) in the simulation, in silico individual and trial (i.e. repeat of the simulation), respectively. The remaining columns each correspond to one molecular species present in the simulated system, and the values correspond to their abundance for the given time, individual and trial; runningtime : a vector giving, for each in silico individual, the running time (in seconds) of the simulations (across all trials); stochmodel : a Julia proxy object, giving the stochastic model used for the simulation. You probably won't ever need to work with this object. We are only interested in the Simulation data-frame. If you try to load one of your simulation files and have a look at this data-frame, it should look something like this (note that I'm using as_tibble() to get a nicer visualisation of the data-frame): as_tibble ( sim $ Simulation ) # A tibble: 4,804 \u00d7 203 time trial R1GCN1 P1GCN1 R4GCN2 P4GCN2 R5GCN2 P5GCN2 R6GCN1 P6GCN1 R2GCN2 P2GCN2 R7GCN2 P7GCN2 R5GCN1 P5GCN1 R3GCN1 P3GCN1 R4GCN1 P4GCN1 R3GCN2 P3GCN2 < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > 1 0 1 0 0 0 0 0 0 0 0 10 100 0 0 0 0 50 500 0 0 50 500 2 1 1 4 0 0 0 0 0 0 0 10 0 1 0 0 0 50 445 0 0 51 455 3 2 1 7 0 0 0 0 0 0 0 9 0 2 0 0 0 51 444 0 0 52 457 4 3 1 13 0 0 0 0 0 0 0 10 0 4 0 0 0 51 448 0 0 52 453 5 4 1 21 1 0 0 0 0 0 0 10 0 6 0 0 0 51 447 0 0 53 452 6 5 1 22 2 0 0 0 0 1 0 10 0 7 0 0 0 50 448 0 0 52 453 7 6 1 24 0 0 0 0 0 1 0 10 0 7 0 0 0 50 446 0 0 52 454 8 7 1 25 0 0 0 0 0 2 0 10 1 7 0 0 0 50 447 0 0 52 454 9 8 1 28 1 0 0 0 0 2 0 10 0 7 0 0 0 51 446 0 0 51 456 10 9 1 34 0 0 0 0 0 2 0 10 0 7 0 0 0 50 445 0 0 51 457 # \u2026 with 4,794 more rows, and 181 more variables: R2GCN1 <dbl>, P2GCN1 <dbl>, R1GCN2 <dbl>, P1GCN2 <dbl>, R7GCN1 <dbl>, P7GCN1 <dbl>, R6GCN2 <dbl>, # P6GCN2 <dbl>, CTC1_P2GCN1_P2GCN1 <dbl>, CTC1_P2GCN1_P2GCN2 <dbl>, CTC1_P2GCN2_P2GCN1 <dbl>, CTC1_P2GCN2_P2GCN2 <dbl>, CTC5_P4GCN1_P4GCN1 <dbl>, # CTC5_P4GCN1_P4GCN2 <dbl>, CTC5_P4GCN2_P4GCN1 <dbl>, CTC5_P4GCN2_P4GCN2 <dbl>, CTC2_P1GCN1_P1GCN1 <dbl>, CTC2_P1GCN1_P1GCN2 <dbl>, # CTC2_P1GCN2_P1GCN1 <dbl>, CTC2_P1GCN2_P1GCN2 <dbl>, CTC6_P3GCN1_CTC5_P4GCN1_P4GCN1 <dbl>, CTC6_P3GCN1_CTC5_P4GCN1_P4GCN2 <dbl>, # CTC6_P3GCN1_CTC5_P4GCN2_P4GCN1 <dbl>, CTC6_P3GCN1_CTC5_P4GCN2_P4GCN2 <dbl>, CTC6_P3GCN2_CTC5_P4GCN1_P4GCN1 <dbl>, # CTC6_P3GCN2_CTC5_P4GCN1_P4GCN2 <dbl>, CTC6_P3GCN2_CTC5_P4GCN2_P4GCN1 <dbl>, CTC6_P3GCN2_CTC5_P4GCN2_P4GCN2 <dbl>, # CTC3_P3GCN1_CTC1_P2GCN1_P2GCN1 <dbl>, CTC3_P3GCN1_CTC1_P2GCN1_P2GCN2 <dbl>, CTC3_P3GCN1_CTC1_P2GCN2_P2GCN1 <dbl>, \u2026 Notice that each species has a suffix on the form GCN1 or GCN2 . This is because sismonr tracks the allele of origin of each molecule. As we are simulating a diploid system, each gene is present in 2 copies (two alleles), and so the RNAs and proteins of a given gene can originate from either of these two alleles. This can be really handy when looking at the impact of mutations of different alleles. In this case however, we don't care about the allele of origin of the different species. Instead, we would rather have the abundance of all RNAs or proteins for a given gene into one column. To obtain that, we can use the sismonr function mergeAlleleAbundance : merged_simulation <- mergeAlleleAbundance ( sim $ Simulation ) as_tibble ( merged_simulation ) # A tibble: 4,804 \u00d7 27 time trial Ind R1 P1 R4 P4 R5 P5 R6 P6 R2 P2 R7 P7 R3 P3 CTC1 CTC5 CTC2 CTC6 CTC3 CTC7 CTC8 CTC4 < dbl > < dbl > < chr > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > 1 0 1 Ind1 0 0 0 0 0 0 0 0 20 200 0 0 100 1000 0 0 0 0 0 0 0 0 2 1 1 Ind1 14 0 0 0 0 0 0 0 20 1 1 0 101 900 0 0 0 0 100 0 0 0 3 2 1 Ind1 16 1 0 0 0 0 0 0 19 1 2 0 103 901 0 0 0 0 100 0 0 0 4 3 1 Ind1 25 0 0 0 0 0 0 0 20 2 4 0 103 901 1 0 0 0 98 0 0 1 5 4 1 Ind1 32 1 0 0 0 0 0 0 20 2 6 0 104 899 0 0 0 0 96 0 0 4 6 5 1 Ind1 39 2 0 0 0 0 1 0 18 0 8 0 102 901 1 0 0 0 96 0 0 4 7 6 1 Ind1 40 0 0 0 0 0 1 0 18 0 8 0 102 900 0 0 0 0 95 0 0 4 8 7 1 Ind1 46 1 0 0 0 0 2 0 18 1 9 0 102 901 0 0 0 0 94 0 0 6 9 8 1 Ind1 54 2 0 0 0 0 2 0 18 1 10 0 102 902 0 0 0 0 93 0 0 7 10 9 1 Ind1 65 0 0 0 0 0 3 0 18 1 10 0 101 902 0 0 0 0 90 0 0 10 # \u2026 with 4,794 more rows, and 2 more variables: CTC9 <dbl>, CTC10 <dbl> This time, we have one column for the RNA abundance of each gene, and idem for the proteins and regulatory complexes. This will be much more practical to create some plots. One more thing to note: in each simulation output, the trial column will be filled with 1 and 2 . This is something to keep in mind when we'll load all the simulation outputs, as ideally we would like to have values from 1 to 500 . The good news is, we can extract the array ID of a given simulation from the file name, using: str_extract ( \"simulation_10_group1.rds\" , \"(?<=_)\\\\d+(?=_)\" ) |> as.numeric () 10 Once we have the array ID of a given file name, we can use a little trick to replace the 1 and 2 in the trial column, as follows: Array ID trial Simulation index 1 1 1 2 2 2 1 3 2 4 3 1 5 2 6 4 1 7 2 8 etc. this conversion is obtained via the formula: Simulation index = trial + 2 x (Array ID - 1) . Importing all simulation results in R \u00b6 The challenge here is we don't have only 1 .rds file; in fact, we've just created 250 of them per group! We will need to use a loop of some sort to import all simulations in R. Listing all the simulation files \u00b6 The first thing we need is a list of all simulation files. There is a function in R just for that: list.files . It will list all files present in the given directory that match a specific pattern. ## Don't forget to update the pattern to reflect how you named your simulation outputs ## For example, replace 'group1' by your group ID sim_files <- list.files ( path = \"./\" , pattern = \"_group1.rds\" ) head ( sim_files ) [ 1 ] \"simulation_1_group1.rds\" \"simulation_10_group1.rds\" \"simulation_100_group1.rds\" \"simulation_101_group1.rds\" [ 5 ] \"simulation_102_group1.rds\" \"simulation_103_group1.rds\" You can check that there are 250 files: n_sim <- length ( sim_files ) n_sim 250 Creating a loop to import all simulations \u00b6 To import each of these simulations, we could use a basic for loop, which would look something like this: Do not run! sim_df <- c () for ( file in sim_files ){ sim <- readRDS ( file ) sim_df <- bind_rows ( sim_df , sim $ Simulation ) } Which is really not ideal from a memory and computational time perspective. However, there is a nice alternative, which relies on the package purrr . Specifically, purrr provides a function, map_dfr , which applies a function to each element of a vector, and concatenates the results into a data-frame. In our case, we can write a function that reads in and formats the simulations result given the file name: read_simulation_results <- function ( file ){ ## Reading in the simulation result sim <- readRDS ( file ) ## Extract the simulation array number sim_id <- str_extract ( file , \"(?<=_)\\\\d+(?=_)\" ) |> as.numeric ( sim_id ) ## Merge abundance of the two alleles of a gene ## and adjust the trial ID res <- mergeAlleleAbundance ( sim $ Simulation ) |> as_tibble () |> mutate ( trial = trial + 2 * ( sim_id - 1 )) return ( res ) } We can then apply this function to each file name (stored in the sim_files vector). As the function returns a data-frame, we can use map_dfr() which: applies the read_simulation_results() function to each element of the sim_files vector; concatenate the returned data-frames into one data-frame. sim_df <- map_dfr ( sim_files , read_simulation_results ) The resulting data-frame sim_df should have 1,201,000 rows: sim_df # A tibble: 1,201,000 \u00d7 27 time trial Ind R1 P1 R4 P4 R5 P5 R6 P6 R2 P2 R7 P7 R3 P3 CTC1 CTC5 CTC2 CTC6 < dbl > < dbl > < chr > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > 1 0 1 Ind1 0 0 0 0 0 0 0 0 20 200 0 0 100 1000 0 0 0 0 2 1 1 Ind1 13 0 0 0 0 0 0 0 20 1 0 0 99 901 0 0 0 0 3 2 1 Ind1 24 1 0 0 0 0 0 0 20 1 1 0 97 901 0 0 0 0 4 3 1 Ind1 37 1 0 0 0 0 0 0 20 1 2 0 98 902 1 0 0 0 5 4 1 Ind1 40 1 0 0 0 0 0 0 20 0 1 0 98 901 0 0 0 0 6 5 1 Ind1 48 1 1 0 0 0 1 0 20 0 4 0 101 900 0 0 1 0 7 6 1 Ind1 51 1 1 0 0 0 1 0 20 1 4 0 101 904 0 0 1 0 8 7 1 Ind1 61 2 2 1 0 0 1 0 20 1 4 0 102 900 0 0 0 0 9 8 1 Ind1 62 1 2 1 0 0 0 0 20 1 5 0 102 901 1 0 0 0 10 9 1 Ind1 60 3 3 1 0 0 0 0 20 0 5 0 99 900 1 0 0 0 # \u2026 with 1,200,990 more rows, and 6 more variables: CTC3 <dbl>, CTC7 <dbl>, CTC8 <dbl>, CTC4 <dbl>, CTC9 <dbl>, CTC10 <dbl> # \u2139 Use `print(n = ...)` to see more rows, and `colnames()` to see all variable names Visualising the simulations \u00b6 Now that we have all 500 simulations into one data-frame, we can easily visualise them! We'll start by using the plotSimulation function from sismonr. We first have to load the sismonr_anthocyanin_system.RData object, which contains the correspondence between species IDs and names, and the colours that we want to use for the plot: load ( \"~/sism_2021/sismonr_anthocyanin_system.RData\" ) plotSimulation ( sim_df , molecules = names ( colours ), mergeComplexes = FALSE , labels = id2names [ names ( colours )], colours = colours ) This should look very similar to the first plot we've made of the result of one simulation. This time however, the average abundance of a given species across all simulations is given with a solid line, and the minimum and maximum abundance across the simulations is represented as a shaded area. This plot is really useful to visualise the biological variation that could be observed experimentally for genetically identical plants. Comparing DFR expression between the two plants \u00b6 One of the interesting results from these simulations is that we can confirm that the expression of anthocyanin biosynthesis-related genes is reduced in the mutant plant. We can visualise it, by creating a graph (say, a histogram, although a boxplot or density plot would work just as well) of the DFR protein abundance at t = 20 minutes (t = 1,200s) in the two plants. As a reminder, the DFR gene is gene 7 in our sismonr GRN. In the simulation data-frame, the column R7 corresponds to the RNAs of gene 7, and the column P7 corresponds to the proteins of gene 7. Have a go at it first! When you are ready, one possible plot is presented below: Example sim_df %>% filter ( time == 1200 ) %>% ## only keep the last time point of each simulation select ( trial , Ind , \"P7\" ) %>% ## we want to focus on DFR proteins abundance ## for a better plot, show wild-type plant first, and give each individual a nice label ## (rather than \"Ind1\" and \"Ind2\") mutate ( Ind = factor ( Ind , levels = c ( \"Ind1\" , \"Ind2\" ), labels = c ( \"Wild-type\" , \"MYBrep overexpressed\" ))) %>% ## Plot section: ggplot ( aes ( x = P7 , fill = Ind )) + geom_histogram ( alpha = 0.5 , colour = \"gray20\" , bins = 50 ) + ## alpha = transparency of the bars scale_fill_brewer ( palette = \"Set1\" , direction = -1 ) + ## choose nice colours labs ( x = \"DFR protein abundance\" , ## x axis title y = \"Count (simulations)\" , ## y axis title fill = \"Plant\" , ## colour legend title title = \"DFR expression is reduced in mutant plants\" , ## informative title subtitle = \"Results from 500 simulations\" ) + ## and subtitle theme_bw () + ## white background, black axes, etc theme ( legend.position = \"bottom\" , plot.title = element_text ( hjust = 0.5 ), ## center the title plot.subtitle = element_text ( hjust = 0.5 ), ## and the subtitle text = element_text ( size = 18 )) ## and increase font size Conclusion \u00b6 Yay, you've reached the end of this workshop! Feel free to make use of this knowledge in your own research projects :) Back to homepage","title":"6. Post-processing"},{"location":"06_post_processing/#6-post-processing","text":"","title":"6. Post-processing"},{"location":"06_post_processing/#checking-that-the-job-array-worked","text":"In the previous section, you have seen how to run a slurm array job. Now it is time to check whether the arrays completed without failing! And if some of the arrays did fail, we would like to identify them to re-run them. As we have seen in the previous sections, the sacct command is useful to assess the status of submitted jobs. However, especially if you have many arrays, it can get difficult to find what you are looking for in the output. Fortunately, there is a (rather lengthy) command which allows you to obtain the ID of the arrays that failed in a format compatible with slurm. The advantage is that you can directly copy the output of this command and paste it in your slurm script for the array option, in order to re-run only those arrays that failed. Type the following command in the terminal: $ sacct -j $JOB_ID -X -n -s TO,F,OOM -o jobid | cut -d \"_\" -f2 | tr -s ' \\n' ',' In the command, you'll need to replace $JOB_ID by your actual slurm job ID. Your turn! Did any of your arrays failed? If so, what would you change before re-running them? Index TO = Timed Out F = Failed OOM = Out Of Memory","title":"Checking that the job array worked"},{"location":"06_post_processing/#interpreting-the-sismonr-output","text":"Now, it is time to analyse the simulations that we generated.","title":"Interpreting the sismonr output"},{"location":"06_post_processing/#copying-the-simulation-outputs-to-relevant-directory","text":"In the simulation script, we made sure to save each simulation into a .RData file. First, make sure that you are in the appropriate directory by typing in the terminal: $ pwd /nesi/project/nesi02659/sismonr_workshop/workingdir/me123/Exercise_5.5 If you do not have results, you can copy the backup files with: $ cp /nesi/project/nesi02659/sismonr_workshop/backup_simulations/simulation_* /nesi/project/nesi02659/sismonr_workshop/workingdir/me123/Exercise_5.5/ of course replacing me123 with your own username.","title":"Copying the simulation outputs to relevant directory"},{"location":"06_post_processing/#looking-at-one-simulation-output","text":"Start a new sismonr Jupyter Notebook in the folder containing the simulations output. In the first cell, add and execute: library ( sismonr ) library ( tibble ) library ( dplyr ) library ( stringr ) library ( purrr ) library ( ggplot2 ) A single .rds file can be then loaded into R with: sim <- readRDS ( \"simulation_1_group1.RData\" ) The output of sismonr is a list composed of 3 elements: Simulation : a data-frame with the simulation results. Columns time , Ind and trial indicate the time (in seconds) in the simulation, in silico individual and trial (i.e. repeat of the simulation), respectively. The remaining columns each correspond to one molecular species present in the simulated system, and the values correspond to their abundance for the given time, individual and trial; runningtime : a vector giving, for each in silico individual, the running time (in seconds) of the simulations (across all trials); stochmodel : a Julia proxy object, giving the stochastic model used for the simulation. You probably won't ever need to work with this object. We are only interested in the Simulation data-frame. If you try to load one of your simulation files and have a look at this data-frame, it should look something like this (note that I'm using as_tibble() to get a nicer visualisation of the data-frame): as_tibble ( sim $ Simulation ) # A tibble: 4,804 \u00d7 203 time trial R1GCN1 P1GCN1 R4GCN2 P4GCN2 R5GCN2 P5GCN2 R6GCN1 P6GCN1 R2GCN2 P2GCN2 R7GCN2 P7GCN2 R5GCN1 P5GCN1 R3GCN1 P3GCN1 R4GCN1 P4GCN1 R3GCN2 P3GCN2 < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > 1 0 1 0 0 0 0 0 0 0 0 10 100 0 0 0 0 50 500 0 0 50 500 2 1 1 4 0 0 0 0 0 0 0 10 0 1 0 0 0 50 445 0 0 51 455 3 2 1 7 0 0 0 0 0 0 0 9 0 2 0 0 0 51 444 0 0 52 457 4 3 1 13 0 0 0 0 0 0 0 10 0 4 0 0 0 51 448 0 0 52 453 5 4 1 21 1 0 0 0 0 0 0 10 0 6 0 0 0 51 447 0 0 53 452 6 5 1 22 2 0 0 0 0 1 0 10 0 7 0 0 0 50 448 0 0 52 453 7 6 1 24 0 0 0 0 0 1 0 10 0 7 0 0 0 50 446 0 0 52 454 8 7 1 25 0 0 0 0 0 2 0 10 1 7 0 0 0 50 447 0 0 52 454 9 8 1 28 1 0 0 0 0 2 0 10 0 7 0 0 0 51 446 0 0 51 456 10 9 1 34 0 0 0 0 0 2 0 10 0 7 0 0 0 50 445 0 0 51 457 # \u2026 with 4,794 more rows, and 181 more variables: R2GCN1 <dbl>, P2GCN1 <dbl>, R1GCN2 <dbl>, P1GCN2 <dbl>, R7GCN1 <dbl>, P7GCN1 <dbl>, R6GCN2 <dbl>, # P6GCN2 <dbl>, CTC1_P2GCN1_P2GCN1 <dbl>, CTC1_P2GCN1_P2GCN2 <dbl>, CTC1_P2GCN2_P2GCN1 <dbl>, CTC1_P2GCN2_P2GCN2 <dbl>, CTC5_P4GCN1_P4GCN1 <dbl>, # CTC5_P4GCN1_P4GCN2 <dbl>, CTC5_P4GCN2_P4GCN1 <dbl>, CTC5_P4GCN2_P4GCN2 <dbl>, CTC2_P1GCN1_P1GCN1 <dbl>, CTC2_P1GCN1_P1GCN2 <dbl>, # CTC2_P1GCN2_P1GCN1 <dbl>, CTC2_P1GCN2_P1GCN2 <dbl>, CTC6_P3GCN1_CTC5_P4GCN1_P4GCN1 <dbl>, CTC6_P3GCN1_CTC5_P4GCN1_P4GCN2 <dbl>, # CTC6_P3GCN1_CTC5_P4GCN2_P4GCN1 <dbl>, CTC6_P3GCN1_CTC5_P4GCN2_P4GCN2 <dbl>, CTC6_P3GCN2_CTC5_P4GCN1_P4GCN1 <dbl>, # CTC6_P3GCN2_CTC5_P4GCN1_P4GCN2 <dbl>, CTC6_P3GCN2_CTC5_P4GCN2_P4GCN1 <dbl>, CTC6_P3GCN2_CTC5_P4GCN2_P4GCN2 <dbl>, # CTC3_P3GCN1_CTC1_P2GCN1_P2GCN1 <dbl>, CTC3_P3GCN1_CTC1_P2GCN1_P2GCN2 <dbl>, CTC3_P3GCN1_CTC1_P2GCN2_P2GCN1 <dbl>, \u2026 Notice that each species has a suffix on the form GCN1 or GCN2 . This is because sismonr tracks the allele of origin of each molecule. As we are simulating a diploid system, each gene is present in 2 copies (two alleles), and so the RNAs and proteins of a given gene can originate from either of these two alleles. This can be really handy when looking at the impact of mutations of different alleles. In this case however, we don't care about the allele of origin of the different species. Instead, we would rather have the abundance of all RNAs or proteins for a given gene into one column. To obtain that, we can use the sismonr function mergeAlleleAbundance : merged_simulation <- mergeAlleleAbundance ( sim $ Simulation ) as_tibble ( merged_simulation ) # A tibble: 4,804 \u00d7 27 time trial Ind R1 P1 R4 P4 R5 P5 R6 P6 R2 P2 R7 P7 R3 P3 CTC1 CTC5 CTC2 CTC6 CTC3 CTC7 CTC8 CTC4 < dbl > < dbl > < chr > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > 1 0 1 Ind1 0 0 0 0 0 0 0 0 20 200 0 0 100 1000 0 0 0 0 0 0 0 0 2 1 1 Ind1 14 0 0 0 0 0 0 0 20 1 1 0 101 900 0 0 0 0 100 0 0 0 3 2 1 Ind1 16 1 0 0 0 0 0 0 19 1 2 0 103 901 0 0 0 0 100 0 0 0 4 3 1 Ind1 25 0 0 0 0 0 0 0 20 2 4 0 103 901 1 0 0 0 98 0 0 1 5 4 1 Ind1 32 1 0 0 0 0 0 0 20 2 6 0 104 899 0 0 0 0 96 0 0 4 6 5 1 Ind1 39 2 0 0 0 0 1 0 18 0 8 0 102 901 1 0 0 0 96 0 0 4 7 6 1 Ind1 40 0 0 0 0 0 1 0 18 0 8 0 102 900 0 0 0 0 95 0 0 4 8 7 1 Ind1 46 1 0 0 0 0 2 0 18 1 9 0 102 901 0 0 0 0 94 0 0 6 9 8 1 Ind1 54 2 0 0 0 0 2 0 18 1 10 0 102 902 0 0 0 0 93 0 0 7 10 9 1 Ind1 65 0 0 0 0 0 3 0 18 1 10 0 101 902 0 0 0 0 90 0 0 10 # \u2026 with 4,794 more rows, and 2 more variables: CTC9 <dbl>, CTC10 <dbl> This time, we have one column for the RNA abundance of each gene, and idem for the proteins and regulatory complexes. This will be much more practical to create some plots. One more thing to note: in each simulation output, the trial column will be filled with 1 and 2 . This is something to keep in mind when we'll load all the simulation outputs, as ideally we would like to have values from 1 to 500 . The good news is, we can extract the array ID of a given simulation from the file name, using: str_extract ( \"simulation_10_group1.rds\" , \"(?<=_)\\\\d+(?=_)\" ) |> as.numeric () 10 Once we have the array ID of a given file name, we can use a little trick to replace the 1 and 2 in the trial column, as follows: Array ID trial Simulation index 1 1 1 2 2 2 1 3 2 4 3 1 5 2 6 4 1 7 2 8 etc. this conversion is obtained via the formula: Simulation index = trial + 2 x (Array ID - 1) .","title":"Looking at one simulation output"},{"location":"06_post_processing/#importing-all-simulation-results-in-r","text":"The challenge here is we don't have only 1 .rds file; in fact, we've just created 250 of them per group! We will need to use a loop of some sort to import all simulations in R.","title":"Importing all simulation results in R"},{"location":"06_post_processing/#listing-all-the-simulation-files","text":"The first thing we need is a list of all simulation files. There is a function in R just for that: list.files . It will list all files present in the given directory that match a specific pattern. ## Don't forget to update the pattern to reflect how you named your simulation outputs ## For example, replace 'group1' by your group ID sim_files <- list.files ( path = \"./\" , pattern = \"_group1.rds\" ) head ( sim_files ) [ 1 ] \"simulation_1_group1.rds\" \"simulation_10_group1.rds\" \"simulation_100_group1.rds\" \"simulation_101_group1.rds\" [ 5 ] \"simulation_102_group1.rds\" \"simulation_103_group1.rds\" You can check that there are 250 files: n_sim <- length ( sim_files ) n_sim 250","title":"Listing all the simulation files"},{"location":"06_post_processing/#creating-a-loop-to-import-all-simulations","text":"To import each of these simulations, we could use a basic for loop, which would look something like this: Do not run! sim_df <- c () for ( file in sim_files ){ sim <- readRDS ( file ) sim_df <- bind_rows ( sim_df , sim $ Simulation ) } Which is really not ideal from a memory and computational time perspective. However, there is a nice alternative, which relies on the package purrr . Specifically, purrr provides a function, map_dfr , which applies a function to each element of a vector, and concatenates the results into a data-frame. In our case, we can write a function that reads in and formats the simulations result given the file name: read_simulation_results <- function ( file ){ ## Reading in the simulation result sim <- readRDS ( file ) ## Extract the simulation array number sim_id <- str_extract ( file , \"(?<=_)\\\\d+(?=_)\" ) |> as.numeric ( sim_id ) ## Merge abundance of the two alleles of a gene ## and adjust the trial ID res <- mergeAlleleAbundance ( sim $ Simulation ) |> as_tibble () |> mutate ( trial = trial + 2 * ( sim_id - 1 )) return ( res ) } We can then apply this function to each file name (stored in the sim_files vector). As the function returns a data-frame, we can use map_dfr() which: applies the read_simulation_results() function to each element of the sim_files vector; concatenate the returned data-frames into one data-frame. sim_df <- map_dfr ( sim_files , read_simulation_results ) The resulting data-frame sim_df should have 1,201,000 rows: sim_df # A tibble: 1,201,000 \u00d7 27 time trial Ind R1 P1 R4 P4 R5 P5 R6 P6 R2 P2 R7 P7 R3 P3 CTC1 CTC5 CTC2 CTC6 < dbl > < dbl > < chr > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > < dbl > 1 0 1 Ind1 0 0 0 0 0 0 0 0 20 200 0 0 100 1000 0 0 0 0 2 1 1 Ind1 13 0 0 0 0 0 0 0 20 1 0 0 99 901 0 0 0 0 3 2 1 Ind1 24 1 0 0 0 0 0 0 20 1 1 0 97 901 0 0 0 0 4 3 1 Ind1 37 1 0 0 0 0 0 0 20 1 2 0 98 902 1 0 0 0 5 4 1 Ind1 40 1 0 0 0 0 0 0 20 0 1 0 98 901 0 0 0 0 6 5 1 Ind1 48 1 1 0 0 0 1 0 20 0 4 0 101 900 0 0 1 0 7 6 1 Ind1 51 1 1 0 0 0 1 0 20 1 4 0 101 904 0 0 1 0 8 7 1 Ind1 61 2 2 1 0 0 1 0 20 1 4 0 102 900 0 0 0 0 9 8 1 Ind1 62 1 2 1 0 0 0 0 20 1 5 0 102 901 1 0 0 0 10 9 1 Ind1 60 3 3 1 0 0 0 0 20 0 5 0 99 900 1 0 0 0 # \u2026 with 1,200,990 more rows, and 6 more variables: CTC3 <dbl>, CTC7 <dbl>, CTC8 <dbl>, CTC4 <dbl>, CTC9 <dbl>, CTC10 <dbl> # \u2139 Use `print(n = ...)` to see more rows, and `colnames()` to see all variable names","title":"Creating a loop to import all simulations"},{"location":"06_post_processing/#visualising-the-simulations","text":"Now that we have all 500 simulations into one data-frame, we can easily visualise them! We'll start by using the plotSimulation function from sismonr. We first have to load the sismonr_anthocyanin_system.RData object, which contains the correspondence between species IDs and names, and the colours that we want to use for the plot: load ( \"~/sism_2021/sismonr_anthocyanin_system.RData\" ) plotSimulation ( sim_df , molecules = names ( colours ), mergeComplexes = FALSE , labels = id2names [ names ( colours )], colours = colours ) This should look very similar to the first plot we've made of the result of one simulation. This time however, the average abundance of a given species across all simulations is given with a solid line, and the minimum and maximum abundance across the simulations is represented as a shaded area. This plot is really useful to visualise the biological variation that could be observed experimentally for genetically identical plants.","title":"Visualising the simulations"},{"location":"06_post_processing/#comparing-dfr-expression-between-the-two-plants","text":"One of the interesting results from these simulations is that we can confirm that the expression of anthocyanin biosynthesis-related genes is reduced in the mutant plant. We can visualise it, by creating a graph (say, a histogram, although a boxplot or density plot would work just as well) of the DFR protein abundance at t = 20 minutes (t = 1,200s) in the two plants. As a reminder, the DFR gene is gene 7 in our sismonr GRN. In the simulation data-frame, the column R7 corresponds to the RNAs of gene 7, and the column P7 corresponds to the proteins of gene 7. Have a go at it first! When you are ready, one possible plot is presented below: Example sim_df %>% filter ( time == 1200 ) %>% ## only keep the last time point of each simulation select ( trial , Ind , \"P7\" ) %>% ## we want to focus on DFR proteins abundance ## for a better plot, show wild-type plant first, and give each individual a nice label ## (rather than \"Ind1\" and \"Ind2\") mutate ( Ind = factor ( Ind , levels = c ( \"Ind1\" , \"Ind2\" ), labels = c ( \"Wild-type\" , \"MYBrep overexpressed\" ))) %>% ## Plot section: ggplot ( aes ( x = P7 , fill = Ind )) + geom_histogram ( alpha = 0.5 , colour = \"gray20\" , bins = 50 ) + ## alpha = transparency of the bars scale_fill_brewer ( palette = \"Set1\" , direction = -1 ) + ## choose nice colours labs ( x = \"DFR protein abundance\" , ## x axis title y = \"Count (simulations)\" , ## y axis title fill = \"Plant\" , ## colour legend title title = \"DFR expression is reduced in mutant plants\" , ## informative title subtitle = \"Results from 500 simulations\" ) + ## and subtitle theme_bw () + ## white background, black axes, etc theme ( legend.position = \"bottom\" , plot.title = element_text ( hjust = 0.5 ), ## center the title plot.subtitle = element_text ( hjust = 0.5 ), ## and the subtitle text = element_text ( size = 18 )) ## and increase font size","title":"Comparing DFR expression between the two plants"},{"location":"06_post_processing/#conclusion","text":"Yay, you've reached the end of this workshop! Feel free to make use of this knowledge in your own research projects :) Back to homepage","title":"Conclusion"},{"location":"07_supplementary/","text":"Supplementary.1 \u00b6 S.1.1 : NeSI Mahuika Jupyter login Follow https://jupyter.nesi.org.nz/hub/login Enter NeSI username, HPC password and 6 digit second factor token Choose server options as below make sure to choose the correct project code nesi02659 , number of CPUs CPUs=4 , memory 8 GB prior to pressing button. S.1.2 : Opening a Jupyter teminal, create a working directory, switch Jupyter file explorer to correct path and open sismonr Jupyter kernel (sismonr/R-4.1.0) Start a terminal session from the JupyterLab launcher When you connect to NeSI JupyterLab you always start in a new hidden directory. To make sure you can find your work next time, you should change to another location. Here we will create a working directory in project nesi02659 workspace for each attendee and then create a symlink from home (~) for easy access. cd ~ mkdir -p /nesi/project/nesi02659/sismonr_workshop/workingdir/ $USER ln -s /nesi/project/nesi02659/sismonr_workshop/workingdir/ $USER ~/sism_2022 Guide Jupyter file explorer (left panel) to above working directory Open 'sismonr/R-4.1.0 kernel' S.1.3 : Restart Jupyter Server Session Only in an instance where the current session was not started according to the instructions on S.1. (above) OR the current session is completely unresponsive S.1.4 : Local setup The sismonr package depends on the programming language Julia . It is preferable to install Julia on your computer before installing sismonr. Installing Julia To install Julia, go to https://julialang.org/downloads/ and follow the instructions. The sismonr package currently works with version >= 1.0. Please make sure to include the Julia executable in your environmental variable PATH. Linux users can use the following command in the terminal: sudo ln -s path_to_julia_folder/bin/julia /usr/local/bin/julia to create a symbolic link to julia inside the /usr/local/bin folder. Windows users can open the Control Panel and go to System > Advanced system settings > Environment variables. Select the PATH variable, click on Edit > New and copy-paste the path path_to_julia_folder/bin . You may need to restart your computer. Installing sismonr sismonr is available on GitHub. You can install sismonr from R or Rstudio using the following commands: library ( devtools ) install_github ( \"oliviaAB/sismonr\" ) Back to homepage","title":"Supplementary.1"},{"location":"07_supplementary/#supplementary1","text":"S.1.1 : NeSI Mahuika Jupyter login Follow https://jupyter.nesi.org.nz/hub/login Enter NeSI username, HPC password and 6 digit second factor token Choose server options as below make sure to choose the correct project code nesi02659 , number of CPUs CPUs=4 , memory 8 GB prior to pressing button. S.1.2 : Opening a Jupyter teminal, create a working directory, switch Jupyter file explorer to correct path and open sismonr Jupyter kernel (sismonr/R-4.1.0) Start a terminal session from the JupyterLab launcher When you connect to NeSI JupyterLab you always start in a new hidden directory. To make sure you can find your work next time, you should change to another location. Here we will create a working directory in project nesi02659 workspace for each attendee and then create a symlink from home (~) for easy access. cd ~ mkdir -p /nesi/project/nesi02659/sismonr_workshop/workingdir/ $USER ln -s /nesi/project/nesi02659/sismonr_workshop/workingdir/ $USER ~/sism_2022 Guide Jupyter file explorer (left panel) to above working directory Open 'sismonr/R-4.1.0 kernel' S.1.3 : Restart Jupyter Server Session Only in an instance where the current session was not started according to the instructions on S.1. (above) OR the current session is completely unresponsive S.1.4 : Local setup The sismonr package depends on the programming language Julia . It is preferable to install Julia on your computer before installing sismonr. Installing Julia To install Julia, go to https://julialang.org/downloads/ and follow the instructions. The sismonr package currently works with version >= 1.0. Please make sure to include the Julia executable in your environmental variable PATH. Linux users can use the following command in the terminal: sudo ln -s path_to_julia_folder/bin/julia /usr/local/bin/julia to create a symbolic link to julia inside the /usr/local/bin folder. Windows users can open the Control Panel and go to System > Advanced system settings > Environment variables. Select the PATH variable, click on Edit > New and copy-paste the path path_to_julia_folder/bin . You may need to restart your computer. Installing sismonr sismonr is available on GitHub. You can install sismonr from R or Rstudio using the following commands: library ( devtools ) install_github ( \"oliviaAB/sismonr\" ) Back to homepage","title":"Supplementary.1"},{"location":"08_supplementary_2/","text":"Supplementary.2 \u00b6 Back to homepage","title":"Supplementary.2"},{"location":"08_supplementary_2/#supplementary2","text":"Back to homepage","title":"Supplementary.2"}]}